<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[git配置之github&gitlab]]></title>
    <url>%2F2019%2F09%2F06%2Fgit%2Fgit%E9%85%8D%E7%BD%AE%E4%B9%8Bgithub%26gitlab%2F</url>
    <content type="text"><![CDATA[记录下github账号与gitlab同一电脑下不同SSH Key的git配置过程:1. github账号SSH Key配置(1) 设置git的名字和邮箱，这点很重要，尤其是对于gitlab的配置12git config --global user.name &quot;xxx&quot;git config --global user.email &quot;xxx&quot;(2) 初始化gitgit init(3) 生成SSH Keyssh-keygen -t rsa -C &quot;your github email&quot;可以看到结果如下，选择默认，passphrase可以根据自己的需要设置，这里直接回车就好。输入cat id_rsa.pub获取公钥或者进入目录复制，贴出本机目录地址1C:\Users\WIND-MILLS\.ssh(4)将公钥（id_rsa.pub）加入到github中，选择setting-&gt;SSH KEY添加即可。2. 配置gitlab SSH Key方法和上面类似，只是生成的Key需要这样输入：1ssh-keygen -t rsa -C &quot;your email&quot; -b 4096这里取名为yst.pub。密码直接回车（三步后两步）3. 配置两种不同的SSH key首先需要将密钥添加到SSH agent中，因为默认只读取id_rsa，为了让SSH识别新的私钥，需将其添加到SSH agent中：1ssh-add ~/.ssh/yst如果出现Could not open a connection to your authentication agent的错误，就试着用以下命令：12ssh-agent bashssh-add ~/.ssh/yst将git bash的工作目录切换到.ssh的默认目录:输入touch config, 创建config文件，添加：123456789Host github HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa Host gitlab HostName gitlab.xxx.x PreferredAuthentications publickey IdentityFile ~/.ssh/yst4. 验证在github&amp;gitlab上的settings里面配置完之后(1) 针对github，输入指令：1ssh -T git@github.com(2) 针对gitlab, 输入指令：1ssh -T git@gitlab]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[“OUT_OF_SERVICE”了解EUREKA的下线/上线]]></title>
    <url>%2F2019%2F09%2F05%2Fspringcloud%2FEUREKA%20%E4%B8%8B%E7%BA%BF%E4%B8%8A%E7%BA%BF%2F</url>
    <content type="text"><![CDATA[EUREKA 下线上线启动项目发现服务请求不到，打开eureka注册中心发线实例被标注了OUT_OF_SERVICE开发环境中，eureka注册中心某服务被注册了多个实例，feign 调用时 服务请求到其他实例上，请求收不到，使用一下命令删除或者强制下线实例：1.DELETE 删除注册实例，但是如果被删除的实例继续注册，还是会存在命令：1http://192.168.x.xx:8761/eureka/apps/xxx/192.168.y.yy192.168.x.xx:8761 为 eurek的地址，xxx 为服务的名称，192.168.y.yy 为需要删除注册的实例别名例如该服务，想要删除 192.168.y.yy 命令为1http://192.168.x.xx:8761/eureka/apps/xxx/192.168.y.yy使用POSTMAN调用delete请求即可1DELETE http://192.168.x.xx:8761/eureka/apps/xxx/192.168.y.yy2.强制下线实例 out_of_service命令：1http://192.168.x.xx:8761/eureka/apps/ORDER/192.168.y.yy/status?value=OUT_OF_SERVICE下线192.168.y.yy的服务，修改ORDER服务的对应实例状态使用postman调用put请求]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>eureka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch移除type]]></title>
    <url>%2F2019%2F08%2F30%2Fes%2FElasticsearch%20%E7%A7%BB%E9%99%A4%20type%2F</url>
    <content type="text"><![CDATA[when1.映射类型的移除计划对于用户来说这是一个大的变化，所以我们尽可能将这个过程变得平滑。这次变更的计划如下：1.1.Elasticsearch 5.6.0在一个索引上设index.mapping.single_type:true会启用单索引-单一类型的行为，而这种行为在6.0中是强制的。在5.6中创建的索引可以使用创建文档间父子关系的新的join字段。1.2.Elasticsearch 6.x5.x中创建的索引可以在6.x中正常工作6.x中创建的索引只允许单个索引中存在单一的类型。任意的名字都可以作为类型，但是只能有一个。_type名不再与_id组合生成_uid字段。_uid字段变成仅仅是_id字段的别名。新创建的索引不再支持旧风格的父子关系，而应该使用join字段。_default_映射类型被标记为不推荐使用。1.3.Elasticsearch 7.xURL中的type参数为可选。比如，索引一个文档不再要求提供文档类型。GET|PUT_mapping API支持一个查询字符串参数（include_type_name），通过这个参数来指定请求体是否应该包含一个类型名的层。默认是true。7.x中没有显式指定类型的索引将会使用默认的_doc类型名。_default_映射类型移除。1.4.Elasticsearch 8.x不再支持URL中的type参数。include_type_name参数默认为false。1.5.Elasticsearch 9.xinclude_type_name参数移除。why2.为什么移除官方解释起初，我们说”索引”和关系数据库的“库”是相似的，“类型”和“表”是对等的这是一个不正确的对比，导致了不正确的假设。在关系型数据库里,”表”是相互独立的,一个“表”里的列和另外一个“表”的同名列没有关系，互不影响。但在类型里字段不是这样的在一个Elasticsearch索引里，所有不同类型的同名字段内部使用的是同一个lucene字段存储。也就是说，上面例子中，user类型的user_name字段和tweet类型的user_name字段是存储在一个字段里的，两个类型里的user_name必须有一样的映射(字段定义)这可能导致一些问题，例如你希望同一个索引中”deleted”字段在一个类型里是存储日期值，在另外一个类型里存储布尔值最后,在同一个索引中，存储仅有小部分字段相同或者全部字段都不相同的文档，会导致数据稀疏，影响Lucene有效压缩数据的能力。因为这些原因，决定从Elasticsearch中移除类型的概念。how3.后续使用3.1.映射类型的可选替代方案每种文档类型一个索引第一种选择就是每个文档类型对应一个索引。你可以不将tweets和users存储于同一个索引，而将它们分别存储于tweets索引和users索引中。索引之间是完全相互独立的，不同索引中的（同名的）字段类型也就不会产生冲突了。这种方式有两个好处：数据更倾向于密集（而不是稀疏），这样就能获益于Lucene的压缩技术。因为同一个索引中的所有的文档代表同一种实体，用于为全文搜索打分的条件统计会更精确。每个索引可以依据其可能的文档存储量级来设置相关的配置：可以对users使用较少的主分片，同时对tweets使用较大数量的主分片。自定义类型字段当然，一个集群中可以创建的主分片的数量是有限制的，所以你可能不想为一个只有几千个文档的集合去浪费一整个分片。这种情况下你可以使用你自己定义的type字段，它看起来和原来的_type工作机制类似。我们使用的user/tweet例子。原来的工作流程可能像下面这样：12345678GET twitter/user,tweet/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;user_name&quot;: &quot;kimchy&quot; &#125; &#125;&#125;123456789101112131415161718192021222324252627282930313233343536373839404142PUT twitter&#123; &quot;mappings&quot;: &#123; &quot;user&quot;: &#123; &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;user_name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;email&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125;, &quot;tweet&quot;: &#123; &quot;properties&quot;: &#123; &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;user_name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;tweeted_at&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125; &#125; &#125; &#125;&#125;PUT twitter/user/kimchy&#123; &quot;name&quot;: &quot;Shay Banon&quot;, &quot;user_name&quot;: &quot;kimchy&quot;, &quot;email&quot;: &quot;shay@kimchy.com&quot;&#125;PUT twitter/tweet/1&#123; &quot;user_name&quot;: &quot;kimchy&quot;, &quot;tweeted_at&quot;: &quot;2019-4-24T09:00:00Z&quot;, &quot;content&quot;: &quot;Types are going away&quot;&#125;GET twitter/tweet/_search&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;user_name&quot;: &quot;kimchy&quot; &#125; &#125;&#125;你可以通过自定义的type字段实现同样的目的：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849PUT twitter&#123; &quot;mappings&quot;: &#123; &quot;doc&quot;: &#123; &quot;properties&quot;: &#123; &quot;type&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;user_name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;email&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;tweeted_at&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125; &#125; &#125; &#125;&#125;PUT twitter/doc/user-kimchy&#123; &quot;type&quot;: &quot;user&quot;, &quot;name&quot;: &quot;Shay Banon&quot;, &quot;user_name&quot;: &quot;kimchy&quot;, &quot;email&quot;: &quot;shay@kimchy.com&quot;&#125;PUT twitter/doc/tweet-1&#123; &quot;type&quot;: &quot;tweet&quot;, &quot;user_name&quot;: &quot;kimchy&quot;, &quot;tweeted_at&quot;: &quot;2019-4-24T09:00:00Z&quot;, &quot;content&quot;: &quot;Types are going away&quot;&#125;GET twitter/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match&quot;: &#123; &quot;user_name&quot;: &quot;kimchy&quot; &#125; &#125;, &quot;filter&quot;: &#123; &quot;match&quot;: &#123; &quot;type&quot;: &quot;tweet&quot; &#125; &#125; &#125; &#125;&#125;在没有映射类型的情况下实现父子关系先前，我们通过将一个映射类型指定为父，另一个或多个映射类型为子来表示父子关系。在没有类型的情况下，我们就不能使用这种语法了。父子关系的特征会向之前那样工作，不同之处在于文档之间这种关系的表示方式变成了使用新的join字段。3.2.新姿势随着 7.0 版本的即将发布，type 的移除也是越来越近了，在 6.0 的时候，已经默认只能支持一个索引一个 type 了，7.0 版本新增了一个参数 include_type_name ，即让所有的 API 是 type 相关的，这个参数在 7.0 默认是 true，不过在 8.0 的时候，会默认改成 false，也就是不包含 type 信息了，这个是 type 用于移除的一个开关。看看最新的使用姿势吧，当 include_type_name 参数设置成 false 后：索引操作：PUT {index}/{type}/{id}需要修改成PUT {index}/_doc/{id}Mapping 操作：PUT {index}/{type}/_mapping 则变成 PUT {index}/_mapping所有增删改查搜索操作返回结果里面的关键字 _type 都将被移除父子关系使用 join 字段来构建12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#创建索引PUT twitter&#123; &quot;mappings&quot;: &#123; &quot;_doc&quot;: &#123; &quot;properties&quot;: &#123; &quot;type&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;name&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;user_name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;email&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;, &quot;tweeted_at&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125; &#125; &#125; &#125;&#125; #修改索引PUT twitter/_doc/user-kimchy&#123; &quot;type&quot;: &quot;user&quot;, &quot;name&quot;: &quot;Shay Banon&quot;, &quot;user_name&quot;: &quot;kimchy&quot;, &quot;email&quot;: &quot;shay@kimchy.com&quot;&#125; #搜索GET twitter/_search&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: &#123; &quot;match&quot;: &#123; &quot;user_name&quot;: &quot;kimchy&quot; &#125; &#125;, &quot;filter&quot;: &#123; &quot;match&quot;: &#123; &quot;type&quot;: &quot;tweet&quot; &#125; &#125; &#125; &#125;&#125; #重建索引POST _reindex&#123; &quot;source&quot;: &#123; &quot;index&quot;: &quot;twitter&quot; &#125;, &quot;dest&quot;: &#123; &quot;index&quot;: &quot;new_twitter&quot; &#125;&#125;]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Head插件安装]]></title>
    <url>%2F2019%2F08%2F30%2Fes%2FHead(%E7%B1%BB%E4%BC%BC%E4%BA%8Emysql%E7%9A%84Navicat)%2F</url>
    <content type="text"><![CDATA[1.安装环境Node.js 10.15.32.安装步骤：2.1.Node.js环境安装head插件要求Node.js环境，并且Node.js的版本 大于等于 6.0。首先，在官网下载Node.js。这里，我直接下载最新版 Node.js 10.15.3。下载地址：https://nodejs.org/en/download/。选择Linux Binaries (x64)，点击下载、解压。解压完成后，然后配置一下环境变量。下面给出我的配置：12export NODE_HOME=/home/tom/data/node-v10.15.3-linux-x64export PATH=$NODE_HOME/bin:$PATH配置好后，执行命令 source /etc/profile 使上面的配置生效。然后执行 npm -v，看到输出 6.4.1。则咱们的Node.js环境安装成功。2.2.head插件安装首先，在GitHub上找到head插件，地址：https://github.com/mobz/elasticsearch-head。将其下载/克隆到本地。下载完成后，进入 elasticsearch-head的目录下，按顺序执行命令：1234# 安装插件；由于需要下载一些数据，所以可能会比较慢。npm install# 启动插件；如果需要后台启动，可以使用 nohup，具体用法请自行百度npm run start按道理，执行上面的命令后，head 插件应该成功安装，并且正常启动。启动后，我们可以通过 localhost:9100 进行访问。但是，我在安装过程中，碰到了以下问题，下面记录下来，并和大家分享，希望能帮到大家。2.3.问题解决2.3.1.问题一1npm ERR! Error: EACCES: permission denied, access &apos;/home/tom/data/elasticsearch-head-master/node_modules&apos;显而易见，这是目录访问权限问题。我的解决办法是：切换到 root 用户，再执行 npm install 进行安装。2.3.2.问题二12Error extracting archivetar (child): bzip2：无法 exec: 没有那个文件或目录这个问题是因为系统中缺少 bzip2 包，直接执行下面命令安装即可：1yum install -y bzip22.3.3.问题三1npm ERR! phantomjs-prebuilt@2.1.16 install: `node install.js`这个我在github的一个issue下找到了答案，执行命令：1npm install phantomjs-prebuilt@2.1.16 --ignore-scripts这样，我们就安装好了 phantomjs-prebuilt@2.1.16，再执行 npm install 即可。到这里时，head插件安装的问题全部都解决了，启动head插件：12npm run startlocalhost:91002.3.4.问题四无法连接esES和head插件实际上属于两个不同的进程，这里存在一个跨域问题。要解决这个问题，需要首先关闭Elasticsearch，在elasticsearch.yml文件后添加两行配置：12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;然后，重新启动ES，刷新 head 插件页面，即可看到现在head插件已经正确查找到了我们的启动那个ES节点至此，我们的Elasticsearch-head插件就安装成功了。]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch7.0新特性]]></title>
    <url>%2F2019%2F08%2F30%2Fes%2Felasticsearch7.0%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[更新Elasticsearch 7.0 默认自带 JDK，不再担心JDK和环境冲突默认分片数改为1，不再是5==ES数据存储结构变化：去除了Typees6时，官方就提到了es7会删除type，并且es6时已经规定每一个index只能有一个type。在es7中使用默认的_doc作为type，官方说在8.x版本会彻底移除type====api请求方式也发送变化，如获得某索引的某ID的文档：GET index/_doc/id其中index和id为具体的值==链接扩展：http://note.youdao.com/noteshare?id=96373b8a5580905e69124ed035a241f3&amp;sub=0D5323D7E5DA426AA7E0360482C1AFE7集群连接变化：TransportClient被废弃以至于，es7的java代码，只能使用restclient。然后，个人综合了一下，对于java编程，建议采用 High-level-rest-client 的方式操作ES集群1.革命性更新1.1.查询相关性速度优化Weak-AND算法在Term Query查询场景有3700%的性能提升。[http://www.aboutyun.com/thread-27003-1-1.html]除了Term检索，Fuzzy，Phrase, Bool And .Bool OR都有大幅的性能提升！123456weak-and算法？核心原理：取TOP N结果集，估算命中记录数。简单来说，一般我们在计算文本相关性的时候，会通过倒排索引的方式进行查询，通过倒排索引已经要比全量遍历节约大量时间，但是有时候仍然很慢。原因是很多时候我们其实只是想要top n个结果，一些结果明显较差的也进行了复杂的相关性计算，而weak-and算法通过计算每个词的贡献上限来估计文档的相关性上限，从而建立一个阈值对倒排中的结果进行减枝，从而得到提速的效果。更快的前 k 个查询：在许多搜索用例中，快速查看查询的前 k 个结果对于用户而言比确切的命中数更重要。例如，如果有人在电子商务网站上搜索产品，他们对 10 个最相关的结果更感兴趣，而不是与搜索查询匹配的其他 120 897 个结果。Elasticsearch 7.0 和 Lucene 8.0 实现了一种新算法 Block-Max WAND，可在巨幅提升检索命中前 k 个结果的速度。1.2.间隔查询(Intervals queries)某些搜索用例（例如，法律和专利搜索）引入了查找单词或短语彼此相距一定距离的记录的需要。Elasticsearch 7.0中的间隔查询引入了一种构建此类查询的全新方式，与之前的方法（跨度查询span queries）相比，使用和定义更加简单。与跨度查询相比，间隔查询对边缘情况的适应性更强。1.3.引入新的集群协调子系统移除 minimum_master_nodes 参数，让 Elasticsearch 自己选择可以形成仲裁的节点。典型的主节点选举现在只需要很短的时间就可以完成。集群的伸缩变得更安全、更容易，并且可能造成丢失数据的系统配置选项更少了。节点更清楚地记录它们的状态，有助于诊断为什么它们不能加入集群或为什么无法选举出主节点。1.4.不再内存溢出升级到 Elasticsearch 7.0 ,新的 Circuit Breaker 在JVM 堆栈层面监测内存使用，Elasticsearch 比之前更加健壮。设置indices.breaker.fielddata.limit的默认值已从JVM堆大小的60％降低到40％。1.5.时间戳纳秒级支持，提升数据精度利用纳秒精度支持加强时间序列用例到目前为止，Elasticsearch仅以毫秒精度存储时间戳。 7.0增加了几个零并带来了纳秒精度，这提高了高频数据采集用户存储和排序所需数据的精度。1.6.其他Function score 2.0：自定义评分是高级搜索用例的基础，人们希望更好地控制相关性和结果排名，Elasticsearch 从早期就提供了这样的能力。7.0 引入了下一代 function score，提供了一种更简单、模块化与灵活的方式来生成每条记录的排名分数。新的模块化结构允许用户混合和匹配一组算术和距离函数，以构建任意函数分值计算，更好地控制结果的分值和排名。此外，Elasticsearch 7.0 中还引入了一个新的聚合来处理地理地图图块，允许用户在地图上放大和缩小，而不会改变结果数据的形状，实现更加平滑地缩放 Elastic Maps；使用纳秒精度存储时序数据的时间戳，允许具有高频数据采集需求的用户可以更加精确地存储和排序他们的数据。显然，7.0的特性远不止这些，更多新版本特性推荐阅读：http://t.cn/EXyStrWhttp://t.cn/EXyStrOhttps://www.elastic.co/guide/en/elasticsearch/reference/current/breaking-changes-7.0.html#_literal_network_breaker_inflight_requests_overhead_literal_increased_to_2]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建cerebro监控]]></title>
    <url>%2F2019%2F08%2F30%2Fes%2FCentos7%20%E6%90%AD%E5%BB%BACerebro%20Elasticsearch%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[Cerebro Elasticsearch简介cerebro是一个开源(MIT许可)elasticsearch web管理工具，使用Scala、Play Framework、AngularJS和Bootstrap构建。cerebro的运行需要java1.8及以上版本。（对比head插件，比head页面美观，也方便使用）项目Github主页 ： https://github.com/lmenezes/cerebro安装12wget https://github.com/lmenezes/cerebro/releases/download/v0.8.1/cerebro-0.8.1.tgztar -zxvf cerebro-0.8.1.tgz配置：1234567891011121314151617181920es = &#123; gzip = true&#125;# Authenticationauth = &#123;type: basic settings: &#123; username = &quot;wind&quot; password = &quot;xxxxx&quot; &#125;&#125;# A list of known hostshosts = [ &#123; host = &quot;http://localhost:9200&quot; name = &quot;WIND-ES&quot; &#125;]启动 ：./bin/cerebro1&gt; 访问,9000端口:http://xxx.xxx:9000/12默认端口为9000，若需要修改端口tee -a /etc/systemd/system/cerebro.service &lt;&lt; ‘EOF’http = {port = “9000”address = “192.168.1.144”}EOF```port暴露的端口address默认为0.0.0.0，设置为0.0.0.0表示对该主机所有网卡开放]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解springcloud]]></title>
    <url>%2F2019%2F08%2F30%2Fspringcloud%2Fspringcloud%2F</url>
    <content type="text"><![CDATA[深入了解springcloud各个组件的协调工作原理相关业务-订单服务的理解（支付订单）创建一个订单，用户支付，订单状态改变库存扣减相应的库存通知仓储中心发货给用户这个的购物增加积分争对上述订单流程，可以得到有几个模块：订单模块、库存模块、存储服务、积分服务1、 Eureka[juˈriːkə]订单服务想要调用库存服务、仓储服务，或者是积分服务，怎么调用？订单服务压根儿就不知道人家库存服务在哪台机器上啊！他就算想要发起一个请求，都不知道发送给谁，有心无力！这时候，就轮到Spring Cloud Eureka出场了。Eureka是微服务架构中的注册中心，专门负责服务的注册与发现。库存服务、仓储服务、积分服务中都有一个Eureka Client组件，这个组件专门负责将这个服务的信息注册到Eureka Server中。说白了，就是告诉Eureka Server，自己在哪台机器上，监听着哪个端口。而Eureka Server是一个注册中心，里面有一个注册表，保存了各服务所在的机器和端口号订单服务里也有一个Eureka Client组件，这个Eureka Client组件会找Eureka Server问一下：库存服务在哪台机器啊？监听着哪个端口啊？仓储服务呢？积分服务呢？然后就可以把这些相关信息从Eureka Server的注册表中拉取到自己本地缓存起来。这时如果订单服务想要调用库存服务，不就可以找自己本地的Eureka Client问一下库存服务在哪台机器？监听哪个端口吗？收到响应后，紧接着就可以发送一个请求过去，调用库存服务扣减库存的那个接口！同理，如果订单服务要调用仓储服务、积分服务，也是如法炮制。 sumEureka Client：负责将这个服务的信息注册到Eureka Server中Eureka Server：注册中心，里面有一个注册表，保存了各个服务所在的机器和端口号2、 Feign[feɪn]Feign Client会在底层根据你的注解，跟你指定的服务建立连接、构造请求、发起靕求、获取响应、解析响应，等等。服务间调用时，不必每次都手写代码首先，如果你对某个接口定义了@FeignClient注解，Feign就会针对这个接口创建一个动态代理接着你要是调用那个接口，本质就是会调用 Feign创建的动态代理，这是核心中的核心Feign的动态代理会根据你在接口上的@RequestMapping等注解，来动态构造出你要请求的服务的地址最后针对这个地址，发起请求、解析响应3、 Ribbon[`riben]说完了Feign，还没完。现在新的问题又来了，如果人家库存服务部署在了5台机器上，如下所示：192.168.169:9000192.168.170:9000192.168.171:9000192.168.172:9000192.168.173:9000Feign怎么知道该请求哪台机器呢？Ribbon就是专门解决这个问题的。它的作用是负载均衡，会帮你在每次请求时选择一台机器，均匀的把请求分发到各个机器上Ribbon的负载均衡默认使用的最经典的Round Robin轮询算法。这是啥？简单来说，就是如果订单服务对库存服务发起10次请求，那就先让你请求第1台机器、然后是第2台机器、第3台机器、第4台机器、第5台机器，接着再来—个循环，第1台机器、第2台机器。。。以此类推。此外，Ribbon是和Feign以及Eureka紧密协作，完成工作的，具体如下：首先Ribbon会从 Eureka Client里获取到对应的服务注册表，也就知道了所有的服务都部署在了哪些机器上，在监听哪些端口号。然后Ribbon就可以使用默认的Round Robin算法，从中选择一台机器Feign就会针对这台机器，构造并发起请求。4、Hystrix在微服务架构里，一个系统会有很多的服务。以本文的业务场景为例：订单服务在一个业务流程里需要调用三个服务。现在假设订单服务自己最多只有100个线程可以处理请求，然后呢，积分服务不幸的挂了，每次订单服务调用积分服务的时候，都会卡住几秒钟，然后抛出—个超时异常。咱们一起来分析一下，这样会导致什么问题？如果系统处于高并发的场景下，大量请求涌过来的时候，订单服务的100个线程都会卡在请求积分服务这块。导致订单服务没有一个线程可以处理请求然后就会导致别人请求订单服务的时候，发现订单服务也挂了，不响应任何请求了上面这个，就是微服务架构中恐怖的服务雪崩问题如上图，这么多服务互相调用，要是不做任何保护的话，某一个服务挂了，就会引起连锁反应，导致别的服务也挂。比如积分服务挂了，会导致订单服务的线程全部卡在请求积分服务这里，没有一个线程可以工作，瞬间导致订单服务也挂了，别人请求订单服务全部会卡住，无法响应。这时就轮到Hystrix闪亮登场了。Hystrix是隔离、熔断以及降级的一个框架。啥意思呢？说白了，Hystrix会搞很多个小小的线程池，比如订单服务请求库存服务是一个线程池，请求仓储服务是一个线程池，请求积分服务是一个线程池。每个线程池里的线程就仅仅用于请求那个服务。这个时候如果别人请求订单服务，订单服务还是可以正常调用库存服务扣减库存，调用仓储服务通知发货。只不过调用积分服务的时候，每次都会报错。但是如果积分服务都挂了，每次调用都要去卡住几秒钟干啥呢？有意义吗？当然没有！所以我们直接对积分服务熔断不就得了，比如在5分钟内请求积分服务直接就返回了，不要去走网络请求卡住几秒钟，这个过程，就是所谓的熔断！那人家又说，兄弟，积分服务挂了你就熔断，好歹你干点儿什么啊！别啥都不干就直接返回啊？没问题，咱们就来个降级：每次调用积分服务，你就在数据库里记录一条消息，说给某某用户增加了多少积分，因为积分服务挂了，导致没增加成功！这样等积分服务恢复了，你可以根据这些记录手工加一下积分。这个过程，就是所谓的降级。5、Zuul说完了Hystrix，接着给大家说说最后一个组件：Zuul，也就是微服务网关。这个组件是负责网络路由的。不懂网络路由？行，那我给你说说，如果没有Zuul的日常工作会怎样？假设你后台部署了几百个服务，现在有个前端兄弟，人家请求是直接从浏览器那儿发过来的。打个比方：人家要请求一下库存服务，你难道还让人家记着这服务的名字叫做inventory-service？部署在5台机器上？就算人家肯记住这一个，你后台可有几百个服务的名称和地址呢？难不成人家请求一个，就得记住一个？你要这样玩儿，那真是友谊的小船，说翻就翻！上面这种情况，压根儿是不现实的。所以一般微服务架构中都必然会设计一个网关在里面，像android、ios、pc前端、微信小程序、H5等等，不用去关心后端有几百个服务，就知道有一个网关，所有请求都往网关走，网关会根据请求中的一些特征，将请求转发给后端的各个服务。6、总结：最后再来总结一下，上述几个Spring Cloud核心组件，在微服务架构中，分别扮演的角色：Eureka：各个服务启动时，EurekaClient都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里Ribbon：服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台Feign：基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求Hystrix：发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题Zuul：如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务以上就是我们通过一个电商业务场景，阐述了Spring Cloud微服务架构几个核心组件的底层原理。 而且有一个网关之后，还有很多好处，比如可以做统一的降级、限流、认证授权、安全，等等。博文地址：https://blog.csdn.net/forezp/article/details/83999882]]></content>
      <categories>
        <category>springcloud</category>
      </categories>
      <tags>
        <tag>springcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Data Elasticsearch]]></title>
    <url>%2F2019%2F08%2F30%2Fes%2FSpring%20Data%20Elasticsearch%EF%BC%88es5.6.3%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Spring Data ElasticsearchElasticsearch提供的Java客户端有一些不太方便的地方：很多地方需要拼接Json字符串，在java中拼接字符串有多恐怖你应该懂的需要自己把对象序列化为json存储查询到结果也需要自己反序列化为对象因此，这里学习下Spring提供的套件Spring Data Elasticsearch，暂不了解原生的Elasticsearch客户端API1.简介Spring Data Elasticsearch是Spring Data项目下的一个子模块。查看 Spring Data的官网：http://projects.spring.io/spring-data/Spring Data的使命是为数据访问提供熟悉且一致的基于Spring的编程模型，同时仍保留底层数据存储的特殊特性。它使得使用数据访问技术，关系数据库和非关系数据库，map-reduce框架和基于云的数据服务变得容易。这是一个总括项目，其中包含许多特定于给定数据库的子项目。这些令人兴奋的技术项目背后，是由许多公司和开发人员合作开发的。Spring Data 的使命是给各种数据访问提供统一的编程接口，不管是关系型数据库（如MySQL），还是非关系数据库（如Redis），或者类似Elasticsearch这样的索引数据库。从而简化开发人员的代码，提高开发效率。包含很多不同数据操作的模块：Spring Data Elasticsearch的页面：https://projects.spring.io/spring-data-elasticsearch/特征：支持Spring的基于@Configuration的java配置方式，或者XML配置方式提供了用于操作ES的便捷工具类ElasticsearchTemplate。包括实现文档到POJO之间的自动智能映射。利用Spring的数据转换服务实现的功能丰富的对象映射基于注解的元数据映射方式，而且可扩展以支持更多不同的数据格式根据持久层接口自动生成对应实现方法，无需人工编写基本操作代码（类似mybatis，根据接口自动得到实现）。当然，也支持人工定制查询2.对比原生APIElasticsearch 原生 API 好处就是可以第一时间用到 Elasticsearch 的新特性。缺点的学习成本高。用 Spring Data 的好处是，用统一的接口，适配所有不同的存储类型，如SQL、NoSQL 等等。缺点是，有时候适配的版本要比原生的 API 要慢。这个取决于 Spring Data Elasticsearch 团队的开发速度了Spring Data ElasticsearchElasticsearch3.2.x6.7.23.1.x6.2.23.0.x5.5.02.1.x2.4.02.0.x2.2.01.3.x1.5.23..创建Demo工程新建一个demo，学习Elasticsearchpom依赖：1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;application.yml文件配置：123456spring: data: elasticsearch: cluster-name: elasticsearch #9300：集群节点间通讯接口 9200：客户端访问接口 cluster-nodes: 192.168.56.101:93004..实体类及注解首先准备好实体类：1234567891011121314151617@Data@Document(indexName = "items", type = "books", shards = 1, replicas = 0)public class Item implements Serializable &#123; @Id private Long id; @Field(type = FieldType.text, analyzer = "ik_max_word") private String title; @Field(type = FieldType.keyword) private String category; @Field(type = FieldType.Double) private Double price; @Field(index = false, type = FieldType.keyword) private String images;映射Spring Data通过注解来声明字段的映射属性，有下面的三个注解：@Document 作用在类，标记实体类为文档对象，一般有两个属性indexName：对应索引库名称type：对应在索引库中的类型shards：分片数量，默认5replicas：副本数量，默认11234567891011String indexName();//索引库的名称，建议以项目的名称命名 String type() default &quot;&quot;;//类型，建议以实体的名称命名 short shards() default 5;//默认分区数 short replicas() default 1;//每个分区默认的备份数 String refreshInterval() default &quot;1s&quot;;//刷新间隔 String indexStoreType() default &quot;fs&quot;;//索引文件存储类型@Id 作用在成员变量，在Elasticsearch里相应于该列就是主键了，在查询时就可以直接用主键查询@Field 作用在成员变量，标记为文档的字段，并指定字段映射属性：type：字段类型，取值是枚举：FieldTypeindex：是否索引，布尔类型，默认是truestore：是否存储，布尔类型，默认是falseanalyzer：分词器名称1234567891011121314151617181920public @interface Field &#123; FieldType type() default FieldType.Auto;#自动检测属性的类型 FieldIndex index() default FieldIndex.analyzed;#默认情况下分词 DateFormat format() default DateFormat.none; String pattern() default &quot;&quot;; boolean store() default false;#默认情况下不存储原文 String searchAnalyzer() default &quot;&quot;;#指定字段搜索时使用的分词器 String indexAnalyzer() default &quot;&quot;;#指定字段建立索引时指定的分词器 String[] ignoreFields() default &#123;&#125;;#如果某个字段需要被忽略 boolean includeInParent() default false;&#125;5.Template索引操作5.1.创建索引和映射创建索引ElasticsearchTemplate中提供了创建索引的API：可以根据类的信息自动生成，也可以手动指定indexName和Settings映射映射相关的API：可以根据类的字节码信息（注解配置）来生成映射，或者手动编写映射这里采用类的字节码信息创建索引并映射：123456789101112131415@RunWith(SpringRunner.class)@SpringBootTest(classes = ItcastElasticsearchApplication.class)public class IndexTest &#123; @Autowired private ElasticsearchTemplate elasticsearchTemplate; @Test public void testCreate()&#123; // 创建索引，会根据Item类的@Document注解信息来创建 elasticsearchTemplate.createIndex(Item.class); // 配置映射，会根据Item类中的id、Field等字段来自动完成映射 elasticsearchTemplate.putMapping(Item.class); &#125;&#125;5.2.删除索引根据类名或索引名删除索引的API。示例：1234@Testpublic void deleteIndex() &#123; esTemplate.deleteIndex("items");&#125;结果：HEAD wind ---4046.Repository文档操作Spring Data 的强大之处，就在于你不用写任何DAO处理，自动根据方法名或类的信息进行CRUD操作。只要你定义一个接口，然后继承Repository提供的一些子接口，就能具备各种基本的CRUD功能。我们只需要定义接口，然后继承它就OK了。12public interface ItemMapper extends ElasticsearchRepository&lt;Item, Long&gt; &#123;&#125;6.1.新增文档12345678@Autowired private ItemMapper itemMapper; @Test public void index() &#123; Item item = new Item(1L, "三体", "科幻", 199.00, "http://image.xxx.com/123.jpg"); itemMapper.save(item); &#125;去页面查询看看：1GET /items/books/1结果：1234567891011121314&#123; "_index": "items", "_type": "books", "_id": "1", "_version": 5, "found": true, "_source": &#123; "id": 1, "title": "时间简史", "category": "科幻", "price": 99, "images": "http://image.xxx.com/123.jpg" &#125;&#125;6.2.批量新增1itemMapper.saveAll(list);6.3.修改文档修改和新增是同一个接口，区分的依据就是id，这一点跟我们在页面发起PUT请求是类似的。6.4.基本查询ElasticsearchRepository提供了一些基本的查询方法：1234567@Test public void testFind() &#123; // 查询全部，并安装价格降序排序 Iterable&lt;Item&gt; items = this.itemMapper.findAll(Sort.by(Sort.Direction.DESC, "price")); //items.forEach(t -&gt; System.out.println(t)); items.forEach(System.out::println); &#125;123456Item(id=6, title=三体3, category=科幻, price=299.0, images=http://image.xxx.com/3453123.jpg)Item(id=1, title=时间简史, category=科幻, price=99.0, images=http://image.xxx.com/3453123.jpg)Item(id=4, title=悲惨世界, category=文学, price=89.0, images=http://image.xxx.com/3453123.jpg)Item(id=5, title=世界上下五千年, category=文学, price=79.0, images=http://image.xxx.com/3453123.jpg)Item(id=2, title=时间都去哪了, category=生活, price=69.0, images=http://image.xxx.com/3453123.jpg)Item(id=3, title=时间管理, category=生活, price=49.0, images=http://image.xxx.com/3453123.jpg)6.5.自定义方法Spring Data 的另一个强大功能，是根据方法名称自动实现功能。比如：你的方法名叫做：findByTitle，那么它就知道你是根据title查询，然后自动帮你完成，无需写实现类。当然，方法名称要符合一定的约定：KeywordSampleElasticsearch Query StringAndfindByNameAndPrice{&quot;bool&quot; : {&quot;must&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}}OrfindByNameOrPrice{&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;price&quot; : &quot;?&quot;}} ]}}IsfindByName{&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}}NotfindByNameNot{&quot;bool&quot; : {&quot;must_not&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}}BetweenfindByPriceBetween{&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}}LessThanEqualfindByPriceLessThan{&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}}GreaterThanEqualfindByPriceGreaterThan{&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}}BeforefindByPriceBefore{&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : null,&quot;to&quot; : ?,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}}AfterfindByPriceAfter{&quot;bool&quot; : {&quot;must&quot; : {&quot;range&quot; : {&quot;price&quot; : {&quot;from&quot; : ?,&quot;to&quot; : null,&quot;include_lower&quot; : true,&quot;include_upper&quot; : true}}}}}LikefindByNameLike{&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}}StartingWithfindByNameStartingWith{&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;?*&quot;,&quot;analyze_wildcard&quot; : true}}}}}EndingWithfindByNameEndingWith{&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;*?&quot;,&quot;analyze_wildcard&quot; : true}}}}}Contains/ContainingfindByNameContaining{&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;name&quot; : {&quot;query&quot; : &quot;**?**&quot;,&quot;analyze_wildcard&quot; : true}}}}}InfindByNameIn(Collection&lt;String&gt;names){&quot;bool&quot; : {&quot;must&quot; : {&quot;bool&quot; : {&quot;should&quot; : [ {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}, {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}} ]}}}}NotInfindByNameNotIn(Collection&lt;String&gt;names){&quot;bool&quot; : {&quot;must_not&quot; : {&quot;bool&quot; : {&quot;should&quot; : {&quot;field&quot; : {&quot;name&quot; : &quot;?&quot;}}}}}}NearfindByStoreNearNot Supported Yet !TruefindByAvailableTrue{&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}}FalsefindByAvailableFalse{&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : false}}}}OrderByfindByAvailableTrueOrderByNameDesc{&quot;sort&quot; : [{ &quot;name&quot; : {&quot;order&quot; : &quot;desc&quot;} }],&quot;bool&quot; : {&quot;must&quot; : {&quot;field&quot; : {&quot;available&quot; : true}}}}例如，来按照价格区间查询，定义这样的一个方法：12345678/** * 根据价格区间查询 * * @param price1 * @param price2 * @return */ List&lt;Item&gt; findByPriceBetween(double price1, double price2);不需要写实现类，直接运行：12345@Test public void queryByPriceBetween() &#123; List&lt;Item&gt; list = this.itemMapper.findByPriceBetween(50.00, 100.00); list.forEach(t -&gt; System.out.println(t)); &#125;虽然基本查询和自定义方法已经很强大了，但是如果是复杂查询（模糊、通配符、词条查询等）,此时只能使用原生查询。7.高级查询7.1.基本查询12345678@Testpublic void testQuery()&#123; // 词条查询 MatchQueryBuilder queryBuilder = QueryBuilders.matchQuery("title", "时间"); // 执行查询 Iterable&lt;Item&gt; items = this.itemMapper.search(queryBuilder); items.forEach(System.out::println);&#125;ItemMapper的search方法需要QueryBuilder参数，elasticSearch为我们提供了一个对象QueryBuilders；QueryBuilders提供了大量的静态方法，用于生成各种不同类型的查询对象，例如：词条、模糊、通配符等QueryBuilder对象。es提供很多可用的查询方式，但是不够灵活。如果用过滤或者聚合查询等就很难了。7.2.自定义查询最基本的match query：1234567891011121314@Testpublic void testNativeQuery()&#123; // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本的分词查询 queryBuilder.withQuery(QueryBuilders.matchQuery("title", "时间")); // 执行搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 打印总条数 System.out.println(items.getTotalElements()); // 打印总页数 System.out.println(items.getTotalPages()); items.forEach(System.out::println);&#125;12345总条数：3总页数：1Item(id=1, title=时间简史, category=科幻, price=99.0, images=http://image.xxx.com/3453123.jpg)Item(id=2, title=时间都去哪了, category=生活, price=69.0, images=http://image.xxx.com/3453123.jpg)Item(id=3, title=时间管理, category=生活, price=49.0, images=http://image.xxx.com/3453123.jpg)NativeSearchQueryBuilder：Spring提供的一个查询条件构建器，帮助构建json格式的请求体Page&lt;item&gt;：默认是分页查询，因此返回的是一个分页的结果对象，包含属性：totalElements：总条数totalPages：总页数Iterator：迭代器，本身实现了Iterator接口，因此可直接迭代得到当前页的数据其它属性7.3.分页查询利用NativeSearchQueryBuilder可以方便的实现分页：123456789101112131415161718192021222324252627@Testpublic void testNativeQuery()&#123; // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本的分词查询 queryBuilder.withQuery(QueryBuilders.termQuery("category", "文学")); // 初始化分页参数 int page = 1; int size = 2; // 设置分页参数 queryBuilder.withPageable(PageRequest.of(page, size)); // 执行搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 打印总条数 System.out.println(items.getTotalElements()); // 打印总页数 System.out.println(items.getTotalPages()); // 每页大小 //2.0.1.RELEASE这里的getSize无返回结果,2.0.4.RELEASE可以 System.out.println(items.getSize()); // 当前页 //2.0.1.RELEASE这里的getNumber无返回结果 System.out.println(items.getNumber()); items.forEach(System.out::println);&#125;结果：123456总条数：4总页数：2每页大小：2当前页：1Item(id=6, title=三体, category=文学, price=199.0, images=http://image.xxx.com/3453123.jpg)Item(id=7, title=三体2, category=文学, price=199.0, images=http://image.xxx.com/12324.jpg)可以发现，Elasticsearch中的分页是从第0页开始。7.4.排序排序也通用通过NativeSearchQueryBuilder完成：123456789101112131415@Testpublic void testSort()&#123; // 构建查询条件 NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 添加基本的分词查询 queryBuilder.withQuery(QueryBuilders.termQuery(&quot;category&quot;, &quot;文学&quot;)); // 排序 queryBuilder.withSort(SortBuilders.fieldSort(&quot;price&quot;).order(SortOrder.DESC)); // 执行搜索，获取结果 Page&lt;Item&gt; items = this.itemRepository.search(queryBuilder.build()); // 打印总条数 System.out.println(items.getTotalElements()); // 遍历 items.forEach(System.out::println);&#125;123454Item(id=6, title=三体, category=文学, price=199.0, images=http://image.xxx.com/3453123.jpg)Item(id=7, title=三体2, category=文学, price=199.0, images=http://image.xxx.com/12324.jpg)Item(id=4, title=悲惨世界, category=文学, price=89.0, images=http://image.xxx.com/3453123.jpg)Item(id=5, title=世界上下五千年, category=文学, price=79.0, images=http://image.xxx.com/3453123.jpg)8.聚合8.1.聚合为桶桶就是分组，比如按照类型category进行分组：12345678910111213141516171819202122@Test public void testAgg() &#123; NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 不查询任何结果 queryBuilder.withSourceFilter(new FetchSourceFilter(new String[]&#123;""&#125;, null)); // 1、添加一个新的聚合，聚合类型为terms，聚合名称为categories，聚合字段为category queryBuilder.addAggregation( AggregationBuilders.terms("categories").field("category")); // 2、查询,需要把结果强转为AggregatedPage类型 AggregatedPage&lt;Item&gt; aggPage = (AggregatedPage&lt;Item&gt;) this.itemMapper.search(queryBuilder.build()); //3.1、解析从结果中取出名为brands的那个聚合，因为是利用String类型字段来进行的term聚合，所以结果要强转为StringTerm类型 StringTerms agg = (StringTerms) aggPage.getAggregation("categories"); // 3.2、获取桶 List&lt;StringTerms.Bucket&gt; buckets = agg.getBuckets(); // 3.3、遍历 for (StringTerms.Bucket bucket : buckets) &#123; // 3.4、获取桶中的key，即类型名称 System.out.println(bucket.getKeyAsString()); // 3.5、获取桶中的文档数量 System.out.println(bucket.getDocCount()); &#125; &#125;123456文学4生活2科幻1关键API：AggregationBuilders：聚合的构建工厂类。所有聚合都由这个类来构建AggregatedPage：聚合查询的结果类。它是Page&lt;T&gt;的子接口;AggregatedPage在Page功能的基础上，拓展了与聚合相关的功能，它其实就是对聚合结果的一种封装，可以对照聚合结果的JSON结构来看。12345678public interface AggregatedPage&lt;T&gt; extends FacetedPage&lt;T&gt;, ScrolledPage&lt;T&gt; &#123; boolean hasAggregations(); //判断结果中是否有聚合 Aggregations getAggregations(); //获取所有聚合形成的map，key是聚合名称 Aggregation getAggregation(String var1); //根据聚合名称，获取指定集合&#125;而返回的结果都是Aggregation[ˌæɡrɪˈɡeɪʃn]类型对象，不过根据字段类型不同，又有不同的子类表示查询的JSON结果与Java类的对照关系（等长虚线为区间）：1234567891011121314151617181920 &quot;aggregations&quot;: &#123; //aggregations聚合结果对象，可以包含多个聚合，对应API中的AggregatedPage &quot;categories&quot;: &#123; //categories 聚合的名称，区分多个聚合的key------&quot;doc_count_error_upper_bound&quot;: 0,----------------------------------------------------- &quot;sum_other_doc_count&quot;: 0, &quot;buckets&quot;: [ //buckets 桶的数组，java中的Bucket集合 &#123; &quot;key&quot;: &quot;文学&quot;, &quot;doc_count&quot;: 4 &#125;, -&#123;------------------------------------------------------------------------ &quot;key&quot;: &quot;生活&quot;, &quot;doc_count&quot;: 2 -&#125;,-------------------一个桶，有key和文档数量，或其他结果取决于聚合类型------- &#123; &quot;key&quot;: &quot;科幻&quot;, &quot;doc_count&quot;: 1 &#125; -----]------------------对应的值是一个对象，在JavaAPI中就是Aggregation对象，也可以是它的子类，StringTerms，LongTerms，DoubleTerms等----------------------------------------------- &#125; &#125;8.2.嵌套聚合，求平均值123456789101112131415161718192021222324252627@Test public void testSubAgg() &#123; NativeSearchQueryBuilder queryBuilder = new NativeSearchQueryBuilder(); // 不查询任何结果 queryBuilder.withSourceFilter(new FetchSourceFilter(new String[]&#123;""&#125;, null)); // 1、添加一个新的聚合，聚合类型为terms，聚合名称为brands，聚合字段为brand queryBuilder.addAggregation( AggregationBuilders.terms("categories").field("category") .subAggregation(AggregationBuilders.avg("priceAvg").field("price")) // 在品牌聚合桶内进行嵌套聚合，求平均值 ); // 2、查询,需要把结果强转为AggregatedPage类型 AggregatedPage&lt;Item&gt; aggPage = (AggregatedPage&lt;Item&gt;) this.itemMapper.search(queryBuilder.build()); // 3、解析 // 3.1、从结果中取出名为brands的那个聚合， // 因为是利用String类型字段来进行的term聚合，所以结果要强转为StringTerm类型 StringTerms agg = (StringTerms) aggPage.getAggregation("categories"); // 3.2、获取桶 List&lt;StringTerms.Bucket&gt; buckets = agg.getBuckets(); // 3.3、遍历 for (StringTerms.Bucket bucket : buckets) &#123; // 3.4、获取桶中的key，即类型名称 3.5、获取桶中的文档数量 System.out.println(bucket.getKeyAsString() + "，共" + bucket.getDocCount() + "本"); // 3.6.获取子聚合结果： InternalAvg avg = (InternalAvg) bucket.getAggregations().asMap().get("priceAvg"); System.out.println("平均售价：" + avg.getValue()); &#125; &#125;123456文学，共4本平均售价：141.5生活，共2本平均售价：59.0科幻，共1本平均售价：99.0]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
        <tag>spring-data-elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch优化]]></title>
    <url>%2F2019%2F08%2F30%2Fes%2FElasticsearch%E4%BC%98%E5%8C%96%E7%BB%8F%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[图Elasticsearch在数据湖中的地位1.Elasticsearch部署建议1.1选择合理的硬件配置，尽可能使用SSDElasticsearch最大的瓶颈往往是磁盘读写性能，尤其是随机读取性能。使用SSD（PCI-E接口SSD卡/SATA接口SSD盘）通常比机械硬盘（SATA盘/SAS盘）查询速度快5~10倍，写入性能提升不明显。对于文档检索类查询性能要求较高的场景，建议考虑SSD作为存储，同时按照1:10的比例配置内存和硬盘。对于日志分析类查询并发要求较低的场景，可以考虑采用机械硬盘作为存储，同时按照1:50的比例配置内存和硬盘。单节点存储数据建议在2TB以内，最大不要超过5TB，避免查询速度慢、系统不稳定。在单机存储1TB数据场景下，SATA盘和SSD盘的全文检索性能对比（测试环境：Elasticsearch5.5.3，10亿条人口户籍登记信息，单机16核CPU、64GB内存，12块6TB SATA盘，2块1.5 TB SSD盘）：磁盘类型|并发数|QPS|平均检索响应时间|50%请求响应时间|90%请求响应时间|IOPS|—|—|—|—|—|—|—|—|—|—SATA盘|10并发|17|563ms|478ms|994ms|1200SATA盘|50并发|64|773ms|711ms|1155ms|1800SATA盘|100并发|110|902ms|841ms|1225ms|2040SATA盘|200并发|84|2369ms|2335ms|2909ms|2400SSD盘|10并发|94|105ms|90ms|200ms|25400SSD盘|50并发|144|346ms|341ms|411ms|66000SSD盘| 100并发|152|654ms|689ms|791ms|60000SSD盘|200并发|210|950ms|1179ms|1369ms|600001.2.给JVM配置机器一半的内存，但是不建议超过32G修改conf/jvm.options配置，-Xms和-Xmx设置为相同的值，推荐设置为机器内存的一半左右，剩余一半留给操作系统缓存使用。jvm内存建议不要低于2G，否则有可能因为内存不足导致ES无法正常启动或内存溢出，jvm建议不要超过32G，否则jvm会禁用内存对象指针压缩技术，造成内存浪费。机器内存大于64G内存时，推荐配置-Xms30g -Xmx30g 。1.3.规模较大的集群配置专有主节点，避免脑裂问题Elasticsearch主节点（master节点）负责集群元信息管理、index的增删操作、节点的加入剔除，定期将最新的集群状态广播至各个节点。在集群规模较大时，建议配置专有主节点只负责集群管理，不存储数据，不承担数据读写压力。1脑裂问题就是集群中出现了多个master，导致集群内部信息混乱，无法对外提供一致信息。解决方案：避免出现多个master====。====根本解决方案：没有。 由于网络原因不可控。关于脑裂的优化：12345678#一个节点多久ping一次，默认1sdiscovery.zen.fd.ping_interval: 1s##等待ping返回时间，默认30sdiscovery.zen.fd.ping_timeout: 10s##ping超时重试次数，默认3次discovery.zen.fd.ping_retries: 3##选举时需要的节点连接数discovery.zen.minimum_master_nodes=N/2+1拓展：Master的选举机制https://blog.csdn.net/xiaoyu_BD/article/details/820163951.3.1.master节点与data节点分离配置如下：123456789# 专有主节点配置(conf/elasticsearch.yml)：node.master:truenode.data: falsenode.ingest:false# 数据节点配置(conf/elasticsearch.yml)：node.master:falsenode.data:truenode.ingest:trueElasticsearch默认每个节点既是候选主节点，又是数据节点。最小主节点数量参数minimum_master_nodes推荐配置为候选主节点数量一半以上，该配置告诉Elasticsearch当没有足够的master候选节点的时候，不进行master节点选举，等master节点足够了才进行选举。例如对于3节点集群，最小主节点数量从默认值1改为2。12# 最小主节点数量配置(conf/elasticsearch.yml)：discovery.zen.minimum_master_nodes: 21.3.2.GC算法master节点采用(CMS)GC算法，即使GC全局回收，也会及时响应。1.3.3.设置discovery.zen.ping_timeoutdiscovery.zen.ping_timeout（默认3秒），默认情况下，一个节点会认为，如果master节点在3秒之内没有应答，那么这个节点就是死掉了，而增加这个值，会增加节点等待响应的时间，从一定程度上会减少误判。1.3.4.设置选举触发条件设置选举触发条件，discovery.zen.minimum_master_nodes:1该参数是用于控制选举行为发生的最小集群主节点数量。当备选主节点的个数大于等于该参数的值，且备选主节点中有该参数个节点认为主节点挂了，进行选举。官方建议为（n/2）+1，n为主节点个数（即有资格成为主节点的节点个数），增大该参数，当该值为2时，我们可以设置master的数量为3，这样，挂掉一台，其他两台都认为主节点挂掉了，才进行主节点选举。1.3.5.修改data节点的默认的master发现方式data节点的默认的master发现方式由multicast修改为unicastdiscovery.zen.ping.multicast.enabled: falsediscovery.zen.ping.unicast.hosts: [&quot;master1&quot;, &quot;master2&quot;, &quot;master3&quot;]1.4.Linux参数调优关闭交换分区，防止内存置换降低性能。 将/etc/fstab 文件中包含swap的行注释掉121.sed -i &apos;/swap/s/^/#/&apos; /etc/fstab2.swapoff -a单用户可以打开的最大文件数量，可以设置为官方推荐的65536或更大些1echo &quot;* - nofile 655360&quot; &gt;&gt; /etc/security/limits.conf单用户内存地址空间1echo &quot;* - as unlimited&quot;&gt;&gt; /etc/security/limits.conf单用户文件大小1echo &quot;* - fsize unlimited&quot; &gt;&gt;/etc/security/limits.conf单用户锁定内存1echo &quot;* - memlock unlimited&quot; &gt;&gt;/etc/security/limits.conf单用户线程数调大1echo &quot;* - nproc 131072&quot; &gt;&gt; /etc/security/limits.conf单进程可以使用的最大map内存区域数量1echo &quot;vm.max_map_count = 655360&quot; &gt;&gt; /etc/sysctl.conf参数修改立即生效1sysctl -p降低tcp alive time，防止无效链接占用链接数1.5.参数调优开启内存锁，禁止swapping执行linux命令(临时生效)1ulimit -l unlimited修改主机配置：/etc/security/limits.conf12* soft memlock unlimited* hard memlock unlimited修改es配置：config/elasticsearch.yml1bootstrap.memory_lock : true调大文件描述符数量执行linux命令(临时生效)1ulimit -n 65535修改linux配置文件：/etc/security/limits.conf12* soft nofile 65536* hard nofile 65536调大最大映射数执行linux命令(临时生效)1sysctl -w vm.max_map_count=262144修改linux配置文件：/etc/sysctl.conf1vm.max_map_count=2621441.6.JVM内存溢出处理防止es节点内存溢出后处于僵死状态且无法恢复，影响整个集群，在进程出现OOM时让进程宕掉，退出ES集群并引发告警，然后重启。在config/jvm.options中增加JVM启动参数：1-XX:+ExitOnOutOfMemoryError==该参数在jdk 1.8.0_92版本上线==1.7.GC调优ElasticSearch本质上是个Java程序，所以配置JVM垃圾回收器本身也是一个很有意义的工作。我们使用JVM的Xms和Xmx参数来提供指定内存大小，本质上提供的是JVM的堆空间大小，当JVM的堆空间不足的时候就会触发致命的OutOfMemoryException。这意味着要么内存不足，要么出现了内存泄露。处理GC问题，首先要确定问题的源头，一般有两种方案：开启ElasticSearch上的GC日志使用jstat命令生成内存Dump关于第一条，在ES的配置文件elasticsearch.yml中有相关的属性可以配置，关于每个属性的用途这里当然说不完。第二条，jstat命令可以帮助我们查看JVM堆中各个区的使用情况和GC的耗时情况。第三条，最后的办法就是将JVM的堆空间转储到文件中去，实质上是对JVM堆空间的一个快照。想了解更多关于JVM本身GC调优方法请参考：link另外，通过修改ES节点的启动参数，也可以调整GC的方式，但是实质上和上述方法是等同的。2.索引性能调优建议2.1.设置合理的索引分片数和副本数索引分片数建议设置为集群节点的整数倍，初始数据导入时副本数设置为0，生产环境副本数建议设置为1（设置1个副本，集群任意1个节点宕机数据不会丢失；设置更多副本会占用更多存储空间，操作系统缓存命中率会下降，检索性能不一定提升）。单节点索引分片数建议不要超过3个，每个索引分片推荐10-40GB大小。索引分片数设置后不可以修改，副本数设置后可以修改。Elasticsearch6.X及之前的版本默认索引分片数为5、副本数为1，从Elasticsearch7.0开始调整为默认索引分片数为1、副本数为1。不同分片数对写入性能的影响（测试环境：7节点Elasticsearch6.3集群，写入30G新闻数据，单节点56核CPU、380G内存、3TB SSD卡，0副本，20线程写入，每批次提交10M左右数据。）：集群索引分片数|单节点索引分片数|写入耗时|—|—|—|—|—|—|—|—2|0/1|600s7|1|327s14|2|258s21|3|211s28|4|211s56|8|214s索引设置-XPUT-H 'Content-Type: application/json' -d '12345678910111213&#123; &quot;settings&quot; : &#123; &quot;refresh_interval&quot;: &quot;30s&quot;, &quot;merge.policy.max_merged_segment&quot;: &quot;1000mb&quot;, &quot;translog.durability&quot;: &quot;async&quot;, &quot;translog.flush_threshold_size&quot;: &quot;2gb&quot;, &quot;translog.sync_interval&quot;: &quot;100s&quot;, &quot;index&quot; : &#123; &quot;number_of_shards&quot; : &quot;21&quot;, &quot;number_of_replicas&quot; : &quot;0&quot; &#125; &#125;&#125;mapping设置：1234567891011121314151617 curl -XPOST http://localhost:9200/fulltext001/doc/_mapping?pretty -H &apos;Content-Type: application/json&apos; -d &apos;&#123; &quot;doc&quot; : &#123; &quot;_all&quot; : &#123; &quot;enabled&quot; : false &#125;, &quot;properties&quot; : &#123; &quot;content&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot; &#125;, &quot;id&quot; : &#123; &quot;type&quot; : &quot;keyword&quot; &#125; &#125; &#125;&#125;curl -XPUT “http://localhost:9200/fulltext001/_settings&quot; -H ‘Content-Type: application/json’ -d’{“number_of_replicas”: 1}2.2.使用批量请求2.2.1 考虑如果你在做大批量导入，考虑通过设置 index.number_of_replicas: 0关闭副本。把每个索引的 index.refresh_interval改到 -1关闭刷新。导入完毕后再开启副本和刷新。2.2.2 说明使用批量请求将产生比单文档索引请求好得多的性能。写入数据时调用批量提交接口，推荐每批量提交5~15MB数据。例如单条记录1KB大小，每批次提交10000条左右记录写入性能较优；单条记录5KB大小，每批次提交2000条左右记录写入性能较优。批量请求接口API：12345678curl -XPOST &quot;http://localhost:9200/_bulk&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;1&quot; &#125; &#125;&#123; &quot;field1&quot; : &quot;value1&quot; &#125;&#123; &quot;delete&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;2&quot; &#125; &#125;&#123; &quot;create&quot; : &#123; &quot;_index&quot; : &quot;test&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_id&quot; : &quot;3&quot; &#125; &#125;&#123; &quot;field1&quot; : &quot;value3&quot; &#125;&#123; &quot;update&quot; : &#123;&quot;_id&quot; : &quot;1&quot;, &quot;_type&quot; : &quot;_doc&quot;, &quot;_index&quot; : &quot;test&quot;&#125; &#125;&#123; &quot;doc&quot; : &#123;&quot;field2&quot; : &quot;value2&quot;&#125; &#125;2.3.通过多进程/线程发送数据单线程批量写入数据往往不能充分利用服务器CPU资源，可以尝试调整写入线程数或者在多个客户端上同时向Elasticsearch服务器提交写入请求。与批量调整大小请求类似，只有测试才能确定最佳的worker数量。可以通过逐渐增加工作任务数量来测试，直到集群上的I / O或CPU饱和。2.4.调大refresh interval在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 refresh 。 默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是近实时搜索:文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。并不是所有的情况都需要每秒刷新。可能你正在使用 Elasticsearch 索引大量的日志文件，你可能想优化索引速度而不是近实时搜索，可以通过设置 refresh_interval，降低每个索引的刷新频率。设置refresh interval API:123456curl -XPUT &quot;http://localhost:9200/index&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;settings&quot; : &#123; &quot;refresh_interval&quot;: &quot;30s&quot; &#125;&#125;refresh_interval 可以在既存索引上进行动态更新。 在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来：12curl -XPUT &quot;http://localhost:9200/index/_settings&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;refresh_interval&quot;: -1 &#125;&apos;12curl -XPUT &quot;http://localhost:9200/index/_settings&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;refresh_interval&quot;: &quot;1s&quot; &#125;&apos;2.5.设计mapping配置合适的字段类型Elasticsearch在写入文档时，如果请求中指定的索引名不存在，会自动创建新索引，并根据文档内容猜测可能的字段类型。但这往往不是最高效的，我们可以根据应用场景来设计合理的字段类型。例如写入一条记录：123456 curl -XPUT &quot;http://localhost:9200/twitter/doc/1?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;user&quot;: &quot;kimchy&quot;, &quot;post_date&quot;: &quot;2009-11-15T13:12:00&quot;, &quot;message&quot;: &quot;Trying out Elasticsearch, so far so good?&quot;&#125;查询Elasticsearch自动创建的索引mapping，会发现将post_date字段自动识别为date类型，但是message和user字段被设置为text、keyword冗余字段，造成写入速度降低、占用更多磁盘空间。1curl -XGET &quot;http://localhost:9200/twitter&quot;12345678910111213141516171819202122232425262728293031323334353637&#123; &quot;twitter&quot;: &#123; &quot;mappings&quot;: &#123; &quot;doc&quot;: &#123; &quot;properties&quot;: &#123; &quot;message&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125;, &quot;post_date&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;user&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;fields&quot;: &#123; &quot;keyword&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ignore_above&quot;: 256 &#125; &#125; &#125; &#125; &#125; &#125;, &quot;settings&quot;: &#123; &quot;index&quot;: &#123; &quot;number_of_shards&quot;: &quot;5&quot;, &quot;number_of_replicas&quot;: &quot;1&quot;, &#125; &#125; &#125;&#125;根据业务场景设计索引配置合理的分片数、副本数，设置字段类型、分词器。如果不需要合并全部字段，禁用_all字段，通过copy_to来合并字段。123456789 curl -XPUT &quot;http://localhost:9200/twitter?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;settings&quot; : &#123; &quot;index&quot; : &#123; &quot;number_of_shards&quot; : &quot;20&quot;, &quot;number_of_replicas&quot; : &quot;0&quot; &#125; &#125;&#125;1234567891011121314151617181920curl -XPOST &quot;http://localhost:9200/twitter/doc/_mapping?pretty&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;doc&quot; : &#123; &quot;_all&quot; : &#123; &quot;enabled&quot; : false &#125;, &quot;properties&quot; : &#123; &quot;user&quot; : &#123; &quot;type&quot; : &quot;keyword&quot; &#125;, &quot;post_date&quot; : &#123; &quot;type&quot; : &quot;date&quot; &#125;, &quot;message&quot; : &#123; &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot; : &quot;cjk&quot; &#125; &#125; &#125;&#125;2.6.索引配置settings:{efresh_interval}：数据写入刷新间隔，默认1s，调整增加该值可以减少写入压力、增加写入速度，如设为6012345&#123;&quot;settings&quot;: &#123; &quot;refresh_interval&quot;: &quot;60s&quot;&#125;&#125;mappings:{dynamic}： 禁止es自动创建字段，仅允许预先设定好的字段存入es，防止索引结构混乱1234567&#123; &quot;mappings&quot;: &#123; &quot;mytype&quot;: &#123; &quot;dynamic&quot;: false &#125; &#125;&#125;all：建议禁用12345&#123;&quot;_all&quot;: &#123; &quot;enable&quot;: false &#125;&#125;keyword字段属性: ingore_above超过多少字符不写入，keyword一般用于精确查询，不能写入太长。123456&#123;&quot;name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot;, &quot;ingore_above&quot;: 1000 &#125; &#125;index属性：将 不作为查询字段的index值设为false12345678&#123; &#123; &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;false&quot; &#125; &#125;&#125;3.查询性能调优建议3.1.使用过滤器缓存和分片查询缓存ES中的查询操作分为2种：查询（query）和过滤（filter），查询默认会计算每个返回文档的得分，然后根据得分排序；而过滤（filter）只会筛选出符合的文档，并不计算得分，且它可以缓存文档。单从性能考虑，过滤比查询更快而且更节省io资源。过滤适合在大范围筛选数据，而查询则适合精确匹配数据。开发时应先使用过滤操作过滤数据，然后使用查询匹配数据默认情况下，Elasticsearch的查询会计算返回的每条数据与查询语句的相关度，但对于非全文索引的使用场景，用户并不关心查询结果与查询条件的相关度，只是想精确的查找目标数据。此时，可以通过filter来让Elasticsearch不计算评分，并且尽可能的缓存filter的结果集，供后续包含相同filter的查询使用，提高查询效率。普通查询：12345678curl -XGET &quot;http://localhost:9200/twitter/_search&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;user&quot;: &quot;kimchy&quot; &#125; &#125;&#125;过滤器(filter)查询：123456789101112curl -XGET &quot;http://localhost:9200/twitter/_search&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: &#123; &quot;match&quot;: &#123; &quot;user&quot;: &quot;kimchy&quot; &#125; &#125; &#125; &#125;&#125;分片查询缓存的目的是缓存聚合、提示词结果和命中数（它不会缓存返回的文档，因此，它只在search_type=count时起作用）。通过下面的参数我们可以设置分片缓存的大小，默认情况下是JVM堆的1%大小，当然我们也可以手动设置在config/elasticsearch.yml文件里:1indices.requests.cache.size: 1%查看缓存占用内存情况(name表示节点名, query_cache表示过滤器缓存，request_cache表示分片缓存，fielddata表示字段数据缓存，segments表示索引段)：1curl -XGET &quot;http://localhost:9200/_cat/nodes?h=name,query_cache.memory_size,request_cache.memory_size,fielddata.memory_size,segments.memory&amp;v&quot;3.2.使用路由routing3.2.1.概念在将数据写入es时，指定一个字段作为路由字段，es会将该字段进行hash计算写入到对应的分片上；查询时根据查询条件中的路由值，直接查找所在的分片，大幅度提高查询速度。需要注意的是：路由字段必须是随机分布，否则会导致分片数据不平均引发的主机存储使用不平均，可以作为路由字段的：如业务流水、省份、系统编码等。3.2.2.说明Elasticsearch写入文档时，文档会通过一个公式路由到一个索引中的一个分片上。默认的公式如下：1shard_num = hash(_routing) % num_primary_shards_routing字段的取值，默认是_id字段，可以根据业务场景设置经常查询的字段作为路由字段。例如可以考虑将用户id、地区作为路由字段，查询时可以过滤不必要的分片，加快查询速度。写入时指定路由：12345curl -XPUT &quot;http://localhost:9200/my_index/my_type/1?routing=user1&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;title&quot;: &quot;This is a document&quot;, &quot;author&quot;: &quot;user1&quot;&#125;&apos;查询时不指定路由，需要查询所有分片：12345678curl -XGET &quot;http://localhost:9200/my_index/_search&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;document&quot; &#125; &#125;&#125;返回结果：1234567891011&#123; &quot;took&quot;: 2, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 5, &quot;successful&quot;: 5, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125; ......&#125;查询时指定路由，只需要查询1个分片：12345678curl -XGET &quot;http://localhost:9200/my_index/_search?routing=user1&quot; -H &apos;Content-Type: application/json&apos; -d&apos;&#123; &quot;query&quot;: &#123; &quot;match&quot;: &#123; &quot;title&quot;: &quot;document&quot; &#125; &#125;&#125;返回结果：1234567891011&#123; &quot;took&quot;: 1, &quot;timed_out&quot;: false, &quot;_shards&quot;: &#123; &quot;total&quot;: 1, &quot;successful&quot;: 1, &quot;skipped&quot;: 0, &quot;failed&quot;: 0 &#125; ......&#125;3.3.强制合并只读索引，关闭历史数据索引只读的索引可以从合并成一个单独的大segment中收益，减少索引碎片，减少JVM堆常驻内存。历史数据索引如果业务上不再支持查询请求，可以考虑关闭索引，减少JVM内存占用。索引 forcemerge API:1curl -XPOST &quot;http://localhost:9200/abc20180923/_forcemerge&quot;索引关闭API:1curl -XPOST &quot;http://localhost:9200/abc2017*/_close&quot;3.4.配置查询聚合节点查询聚合节点可以发送粒子查询请求到其他节点，收集和合并结果，以及响应发出查询的客户端。通过给查询聚合节点配置更高规格的CPU和内存，可以加快查询运算速度、提升缓存命中率。某客户使用25台8核CPU32G内存节点ELasticsearch集群，查询QPS在4000左右。增加6台16核CPU32G内存节点作为查询聚合节点，观察服务器CPU、JVM堆内存使用情况，并调整缓存、分片、副本参数，查询QPS达到12000。1234# 查询聚合节点配置(conf/elasticsearch.yml)：node.master: falsenode.data: falsenode.ingest:false3.5.设置查询读取记录条数和字段3.5.1.避免深分页查询ES集群的分页查询支持from和size参数，查询的时候，每个分片必须构造一个长度为from+size的优先队列，然后回传到网关节点，网关节点再对这些优先队列进行排序找到正确的size个文档。假设在一个有6个主分片的索引中，from为10000，size为10，每个分片必须产生10010个结果，在网关节点中汇聚合并60060个结果，最终找到符合要求的10个文档。由此可见，当from足够大的时候，就算不发生OOM，也会影响到CPU和带宽等，从而影响到整个集群的性能。所以应该避免深分页查询，尽量不去使用。3.5.2.示例限制是为了保证es集群的稳定性。限制的内容包括：查询范围、单次查询数量等，过大的查询范围不仅会导致查询效率低，而且会是es集群资源耗费急剧增加，甚至引起es集群崩溃；单次查询数量限制是为了保证内存不会被查询内存大量占用，就是分页原理，es默认可以查询10000条数据。默认的查询请求通常返回排序后的前10条记录，最多一次读取10000条记录，通过from和size参数控制读取记录范围，避免一次读取过多的记录。通过_source参数可以控制返回字段信息，尽量避免读取大字段。查询请求示例：1234567891011121314151617181920curl -XGET http://localhost:9200/fulltext001/_search?pretty -H &apos;Content-Type: application/json&apos; -d &apos; &#123; &quot;from&quot;: 0, &quot;size&quot;: 10, &quot;_source&quot;: &quot;id&quot;, &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123;&quot;match&quot;: &#123;&quot;content&quot;:&quot;xxx&quot;&#125;&#125; ] &#125; &#125;, &quot;sort&quot;: [ &#123; &quot;id&quot;: &#123; &quot;order&quot;: &quot;asc&quot; &#125; &#125; ]&#125;3.6.避免前缀模糊匹配Elasticsearch默认支持通过*?正则表达式来做模糊匹配，如果在一个数据量超过10亿条的索引上执行模糊匹配，尤其是前缀模糊匹配，通常耗时会比较长，甚至可能导致内存溢出。尽量避免在高并发查询请求的生产环境执行这类操作。某客户需要对车牌号进行模糊查询，通过查询请求”车牌号:A8848“查询时，往往导致整个集群负载较高。通过对数据预处理，增加冗余字段”车牌号.keyword”，并事先将所有车牌号按照1元、2元、3元…7元分词后存储至该字段，字段存储内容示例:沪,A,8,4,沪A,A8,88,84,48,沪A8…沪A88488。通过查询”车牌号.keyword:A8848”即可解决原来的性能问题。3.7.避免索引稀疏Elasticsearch6.X之前的版本默认允许在一个index下面创建多个type，Elasticsearch6.X及之后的版本只允许创建一个type。在一个type下面创建多个字段不一样的type，或者将几百个字段不一样的索引合并到一个索引中，会导致索引稀疏问题。对于索引优化可以提前创建索引，避免索引稀疏，index中的document结构最好保持一致，如果document结构不一致，建议分index，用一个少量shard的index存放field格式不同的document。建议每个索引下只创建一个type，字段不一样的数据分别独立创建index，不要合并成一个大索引。每个查询请求根据需要去读取相应的索引，避免查询大索引扫描全部记录，加快查询速度。扩展：在加载大量数据使refresh_interval=-1，index.number_of_replicas=0，索引完成后再设回来。Laod和IO压力不大的情况下，用bulk比单条的PUT/DELETE操作索引效率更高。调整index buffer的大小，若不需要field的打分，则可以禁用norms；同样的若不需要sort或aggregate的field，则可以把doc_value属性禁用。对于查询优化可以使用routing提升一维度数的查询速度；通过limit限制，避免返回太大量的搜索结果集；如果heap压力不大，可适当增加node query cache；增加shard备份可提高查询并发能力，但要注意node上的shard总量；最后是定期合并segment。3.8.扩容集群节点个数、升级节点规格通常服务器节点数越多，服务器硬件配置规格越高，Elasticsearch集群的处理能力越强。在不同节点规模下的查询性能测试（测试环境：Elasticsearch5.5.3集群，单节点16核CPU、64G内存、2T SSD盘，10亿条人口户籍登记信息，数据大小1TB。）：集群节点数|副本数|10并发检索平均响应时间|50并发检索平均响应时间|100并发检索平均响应时间|200并发检索平均响应时间|200并发QPS|200并发CPU使用率|200并发CPU IO等待|—|—|—|—|—|—|—|—|—|—1|0|77ms|459ms|438ms|1001ms|200|16%|52%3|0|38ms|103ms|162ms|298ms|669|45%|34%|3|2|271ms|356ms|577ms|818ms|244|19%|54%|10|0|21ms|36ms|48ms|81ms|2467|40%|10%|不同集群节点规模写入性能测试（测试环境：Elasticsearch6.3.2集群，单节点16核CPU、64G内存、2T SSD盘，10亿条人口户籍登记信息，单条记录1KB，数据集大小1TB，20个并发写入线程。）：集群节点数|副本数|写入TPS|耗时|集群CPU使用率|—|—|—|—|—|—|—|—|—|—10|0|88945|11242s|50%50|0|180638|5535s|20%3.9.数据生命周期es中的开启状态的索引都会占用堆内存来存储倒排索引，过多的索引会导致集群整体内存使用率多大，甚至引起内存溢出。所以需要根据自身业务管理历史数据的生命周期，如近3个月的数据开启用于快速查询；过去3-6月的数据索引关闭以释放内存，需要时再开启；超过6个月的可以生成快照保存至hdfs并删除索引，需要的时候从hdfs选择需要的索引恢复至集群中进行查询生产上常常使用logstash+索引模板的方式按照一定时间创建新的索引，例如按天创建索引，索引的命名可能是index-yyyy-mm-dd，每天生产不同的索引，清除历史数据时可直接关闭或删除需要注意的是：如何按照logstash默认的时间分割索引会有8个小时的误差，所以需要在logstash中将真实数据中的时间字段作为分割条件，保障按照业务时间分割索引4.实时性要求高的查询走DB对于ES写入机制的有了解的同学可能会知道，新增的文档会被收集到Indexing Buffer，然后写入到文件系统缓存中，到了文件系统缓存中就可以像其他的文件一样被索引到。然而默认情况文档从Indexing Buffer到文件系统缓存（即Refresh操作）是每秒分片自动刷新，所以这就是我们说ES是==近实时搜索==而非实时的原因：文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。举例：当前订单系统ES采用的是默认Refresh配置，故对于那些订单数据实时性比较高的业务，直接走数据库查询，保证数据的准确性。5. ES 查询耗时很长，响应时间过久，该怎么做（类比mysql执行计划分析）包含但不限于：Nested慢查询、集群查询慢、range查询慢等问题。1）可以用 profile 来查看具体是哪里执行慢https://www.elastic.co/guide/en/elasticsearch/reference/current/search-profile.html2）能用 filter 的都用 filter，减少打分的查询，比如你 must 里面的很多都是可以用 filter 来做的，根据上面的文档来优化。两个维度每当我们得到这些类型的问题时，我们首先要深入研究两个主要方面：配置维度 - 查看当前系统资源和默认Elasticsearch选项。开发维度 - 查看查询，其结构以及要搜索的数据的映射（Mapping）。我们将首先关注开发方面的问题。 我们将获得慢查询，讨论DSL查询语言，并查看有助于改进Elasticsearch查询的小型常规选项。日志12345671[2018-05-21T12:35:53,352][DEBUG ][index.search.slowlog.query] 2[DwOfjJF] [blogpost-slowlogs][4] took[1s], took_millis[0], types[], 3stats[], search_type[QUERY_THEN_FETCH], total_shards[5], 4source[&#123;&quot;query&quot;:&#123;&quot;match&quot;:&#123;&quot;name&quot;:&#123;&quot;query&quot;:&quot;hello world&quot;,5 &quot;operator&quot;:&quot;OR&quot;,&quot;prefix_length&quot;:0,&quot;max_expansions&quot;:50,6&quot;fuzzy_transpositions&quot; :true,&quot;lenient&quot;:false,&quot;zero_terms_query&quot;:7 &quot;NONE&quot;,&quot;boost&quot;:1.0&#125;&#125;&#125;,&quot;sort&quot;:[&#123;&quot;price&quot;: &#123;&quot;order&quot;:&quot;desc&quot;&#125;&#125;]&#125;],通过分解的日志可以看到1234567891 日期2 时间戳 3 日志级别 4 慢速类型 5 节点名称 6 索引名称 7 分片号 8 时间花费 9 查询的主体（_source&gt;）一旦我们获得了我们认为花费的时间太长的查询，我们就可以使用一些工具来分解查询：工具1：Profile APIProfile API提供有关搜索的信息页面，并分解每个分片中发生的情况，直至每个搜索组件（match/range/match_phrase等）的各个时间。 搜索越详细，_profile输出越详细。工具2：Kibana profiling 工具这与_profileAPI密切相关。 它提供了各个搜索组件的完美的可视化效果表征各个分解阶段以及各阶段查询的时间消耗。 同样，这可以轻松选择查询的问题区域。摘自 : https://cloud.tencent.com/developer/article/13576986.OP关注运维Elasticsearch集群主要关注一下几个方面：集群健康状态。集群索引和搜索性能。节点CPU、memory以及disk的使用情况。集群健康状态分为三种，集群green代表健康，集群yellow主要是有replica shard未分配，但不影响集群正常使用，集群red主要是因为有primary shard未分配，会影响集群正常使用。主要原因是集群node disk使用率超过默认值85%，这样一来新的shard就无法分配。这种情况可以通过以下方式查看：通过api GET/_cat/allocation查看node的磁盘使用率。通过api GET/_cluster/settings查看cluster.routing.allocation.enable是否被禁止。通过api GET/_cluster/allocation/explain?pretty查看shard未分配到node的具体原因。参考：Elasticsearch参考[7.3] »如何 »调整搜索速度https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html 等Organized from https://elasticsearch.cn/]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch（一）]]></title>
    <url>%2F2019%2F08%2F30%2Fes%2FElasticsearch(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[背景大规模数据的检索解决查询瓶颈和写入瓶颈传统数据库a. 通过主从备份解决数据安全性问题b. 通过数据库代理中间件心跳监测，解决单点故障问题c. 通过代理中间件将查询语句分发到各个slave节点进行查询，并汇总结果非关系型数据库对于Nosql数据库，以mongodb为例，其它原理类似：a. 通过副本备份保证数据安全性b. 通过节点竞选机制解决单点问题c. 先从配置库检索分片信息，然后将请求分发到各个节点，最后由路由节点合并汇总结果方案存储数据时按有序存储将数据和索引分离压缩数据———————–引出es————————–1.Elasticsearch介绍和安装1.1.简介1.1.1.ElasticElastic官网Elastic有一条完整的产品线及解决方案：Elasticsearch、Kibana、Logstash等，前面说的三个就是大家常说的ELK技术栈。elasticsearch：后台分布式存储以及全文检索logstash: 日志加工、“搬运工”kibana：数据可视化展示。1ELK架构为数据分布式存储、可视化查询和日志解析创建了一个功能强大的管理链。 三者相互配合，取长补短，共同完成分布式大数据处理工作。1.1.2.ElasticsearchElasticsearch官网ElasticSearch 的实现原理主要分为以下几个步骤，首先用户将数据提交到Elastic Search 数据库中，再通过分词控制器去将对应的语句分词，将其权重和分词结果一并存入数据，当用户搜索数据时候，再根据权重将结果排名，打分，再将返回结果呈现给用户。`如上所述，Elasticsearch具备以下特点：分布式实时文件存储，可将每一个字段存入索引，使其可以被检索到。实时分析的分布式搜索引擎。分布式：索引分拆成多个分片，每个分片可有零个或多个副本。集群中的每个数据节点都可承载一个或多个分片，并且协调和处理各种操作可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。也可以运行在单台PC上无需人工搭建集群（solr就需要人为配置，使用Zookeeper作为注册中心）负载再平衡和路由在大多数情况下自动完成。Restful风格，一切API都遵循Rest原则，容易上手近实时搜索，数据更新在Elasticsearch中几乎是完全同步的。支持插件机制，分词插件、同步插件、Hadoop插件、可视化插件等。1.1.3.版本目前Elasticsearch最新的版本有7.3了，这里测试使用的版本5.3.6，需要虚拟机JDK1.8及以上1.1.4.应用场景新系统开发尝试使用ES作为存储和检索服务器场景一：使用Elasticsearch作为主要的后端场景二：在现有系统中增加elasticsearch场景三：使用elasticsearch和现有的工具引用现有系统升级需要支持全文检索服务，需要使用ES典型记录和日志分析从Beats，Logstash到Ingest Nodes，Elasticsearch为您提供了大量的选项，可以在任何地方获取数据并将其索引化。然后，使用Kibana工具使您能够创建丰富的仪表板和分析，而Curator使得您自动化管理索引的生命周期。采集和组合公共数据与日志数据一样，Elastic Stack拥有大量工具，可以轻松抓取和索引远程数据。此外，与大多数文档存储一样，非严格的模式使Elasticsearch可以灵活地接收多个不同的数据源，并能使得这些数据可以管理和搜索。事件数据和指标Elasticsearch还可以很好地处理时间序列数据，如指标（metrics ）和应用程序事件。这是另一个巨大的Beats生态系统允许您轻松获取常见应用程序数据的区域。无论您使用何种技术，Elasticsearch都有很好的机会获取开箱即用的指标和事件…，添加该功能非常简单。数据可视化凭借大量的图表选项，地理数据的平铺服务和时间序列数据的TimeLion，Kibana是一款功能强大且易于使用的可视化工具。对于上面的每个用例，Kibana都会处理 一些可视化组件。一旦您对各种数据提取工具感到满意，您就会发现Elasticsearch + Kibana将成为您可视化数据的首选工具。全文搜索1.1.5.社区国外网站：https://discuss.elastic.co/国内网站：https://elasticsearch.cn/1.2.安装和配置为了模拟线上，在linux下安装Elasticsearch。出于安全考虑，elasticsearch默认不允许以root账号运行。这里创建个一般管理员账号用来启动es创建用户：sh useradd wind设置密码：passwd xxxxxx切换用户：su - wind1wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.3.6-linux-x86_64.tar.gz上传解压缩：tar -zxvf elasticsearch-5.3.6.tar.gz方便管理可以把目录重命名：mv elasticsearch-5.6.3 elasticsearch1.2.1.修改配置进入config目录：cd config需要修改的配置文件有两个：jvm.optionsElasticsearch基于Lucene的，而Lucene底层是java实现，因此需要配置jvm参数。编辑jvm.options：vim jvm.options默认配置如下：12-Xms1g-Xmx1g调小一些：12-Xms512m-Xmx512melasticsearch.yml修改数据和日志目录：12path.data: /home/wind/elasticsearch/data # 数据目录位置path.logs: /home/wind/elasticsearch/logs # 日志目录位置把data和logs目录修改指向了elasticsearch的安装目录。但是这两个目录并不存在，因此需要创建出来。进入elasticsearch的根目录，然后创建：12mkdir datamkdir logs修改绑定的ip(必要)：1network.host: 0.0.0.0 # 绑定到0.0.0.0，允许任何ip来访问开启跨域12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;默认只允许本机访问，修改为0.0.0.0后则可以远程访问目前我们是做的单机安装，如果要做集群，只需要在这个配置文件中添加其它节点信息即可。elasticsearch.yml的其它可配置信息：属性名说明cluster.name配置elasticsearch的集群名称，默认是elasticsearch。建议修改成一个有意义的名称。node.name节点名，es会默认随机指定一个名字，建议指定一个有意义的名称，方便管理path.conf设置配置文件的存储路径，tar或zip包安装默认在es根目录下的config文件夹，rpm安装默认在/etc/ elasticsearchpath.data设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开path.logs设置日志文件的存储路径，默认是es根目录下的logs文件夹path.plugins设置插件的存放路径，默认是es根目录下的plugins文件夹bootstrap.memory_lock设置为true可以锁住ES使用的内存，避免内存进行swapnetwork.host设置bind_host和publish_host，设置为0.0.0.0允许外网访问http.port设置对外服务的http端口，默认为9200。transport.tcp.port集群结点之间通信端口discovery.zen.ping.timeout设置ES自动发现节点连接超时的时间，默认为3秒，如果网络延迟高可设置大些discovery.zen.minimum_master_nodes主结点数量的最少值 ,此值的公式为：(master_eligible_nodes / 2) + 1 ，比如：有3个符合要求的主结点，那么这里要设置为21.2.2.启动进入elasticsearch/bin目录输入命令：1./elasticsearch如发现报错了，启动失败，参考：链接：解决启动报错问题或者：[1]. link1[2].link2所有错误修改完毕，重启终端，否则配置无效。./elasticsearch 直接启动./elasticsearch -d 后台启动判断是否启动成功，可执行如下命令，查看是否启用9200端口即可ss -tanl可以看到绑定了两个端口:9300：集群节点间通讯接口9200：客户端访问接口在浏览器中访问：http://192.168.56.101:92001.2.3 集群搭建(基于7.1.0)环境CentOS 7 Elasticsearch 7.1.0 单机搭建，一主两从步骤12345# 首先创建 elasticsearch-slave 文件夹mkdir /usr/java/elasticsearch-slave# 我本地的ES路径为 /usr/java//elasticsearch-7.1.0 ,使用下面的命令将其复制两份cp -r /usr/java/elasticsearch-7.1.0 /usr/java/elasticsearch-slave/slave1cp -r /usr/java/elasticsearch-7.1.0 /usr/java/elasticsearch-slave/slave2master节点配置：12345678910111213141516171819202122232425# 集群名称cluster.name: &quot;es_cluster&quot; # 节点名称,这儿我直接取名为 masternode.name: master# 是否可以成为master节点node.master: true# 是否允许该节点存储数据,默认开启node.data: true # 网络绑定,这里我绑定 0.0.0.0,支持外网访问network.host: 0.0.0.0 # 设置对外服务的http端口，默认为9200http.port: 9200 # 支持跨域访问http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; # 设置节点间交互的tcp端口,默认是9300transport.tcp.port: 9300 # 手动指定可以成为 mater 的所有节点的 name 或者 ip，这些配置将会在第一次选举中进行计算cluster.initial_master_nodes: [&quot;127.0.0.1&quot;]Slave节点配置：12345678910111213141516171819202122# 集群名称，处于同一个集群所有节点，该名称必须相同cluster.name: &quot;es_cluster&quot; # 节点名称,这儿我直接取名为 slave1node.name: slave1# 是否可以成为master节点node.master: false# 是否允许该节点存储数据,默认开启node.data: true # 网络绑定,这里我绑定 0.0.0.0,支持外网访问network.host: 0.0.0.0 # 设置对外服务的http端口，默认为9200，这里我们修改为 9201，不然会有端口冲突http.port: 9201 # 支持跨域访问http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; # 集群发现discovery.seed_hosts: [&quot;127.0.0.1:9300&quot;]修改完后，启动 slave1/bin/elasticsearch即可。slave2配置：slave2配置和slave1的配置大多相同，只需要修改下面几个配置：12345# 节点名称,这儿我直接取名为 slave2node.name: slave2 # 设置对外服务的http端口，默认为9200，这里设置为 9202http.port: 9202这样，我们在本机就启动了一个ES集群，1个master节点，2个slave节点。在ES 7.0.0中，官方文档明确指出，和 集群发现(Discovery)有关的配置主要由下面两个，下面一段节选、翻译自官方文档：1234567discovery.seed_hosts开箱即用，再没有任何 Network 配置时，Elasticsearch将会自动获取可用的loopback addresses，并且会自动扫描 9300 - 9305 的本地端口尝试连接到运行在同一服务器上的其他节点。这提供了一种不需要不需要任何配置的集群体验。当您想要与其他主机上的节点组成群集时，你必须使用 discovery.seed_hosts 来提供群集中可以成为master ，可能存在并且可以连接到的其他节点的列表，以便为discovery process提供seed(使得 discovery process 能够发现节点)。此设置通常应包含群集中所有可以成为master节点的地址。需要注意的是，IPv6主机必须放在括号内。此设置的默认值为127.0.0.1，[::1]。cluster.initial_master_nodes当你第一次启动全新的Elasticsearch集群时，会有一个集群引导(cluster bootstrapping)步骤，这个步骤会确定一个 在第一次选举中 投票被计数的、并且可以成为 master节点的集合。在开发模式，如果没有配置 discovery settings，该步骤由节点自身自动执行。因为这种自动引导本质上是不安全的，当您在生产模式下启动一个全新的集群时，你必须显式指定那些可以成为master节点的名称或者IP地址，这些节点应该在第一次选举中计算选票数。启动时data目录下的文件可能会冲突，删掉报错的ES目录下的 data 目录，重新启动ES。参考1.3.插件和工具1.3.1.KibanaKibana是一个基于Node.js的Elasticsearch索引库数据统计工具，可以利用Elasticsearch的聚合功能，生成各种图表，如柱形图，线状图，饼图等。而且还提供了操作Elasticsearch索引数据的控制台，并且提供了一定的API提示，非常有利于我们学习Elasticsearch的语法。12Kibana的汉化，从Kibana 6.8 和 ES 7.0开始支持。通过在 `kibana.yml`文件中，增加 i18n.locale: &quot;zh-CN&quot;，就支持中文显示了。1.3.1.1.安装因为Kibana依赖于node，虚拟机没有安装node，而window中安装过。选择在window下使用kibana。版本与elasticsearch保持一致，也是5.6.3kibana下载地址解压到特定目录即可1.3.1.2.配置运行进入安装目录下的config目录，修改kibana.yml文件：修改elasticsearch服务器的地址：1elasticsearch.url: &quot;http://192.168.91.128:5601&quot;kibana的服务如何在后台运行? |nuhup bin/kibana 或者设置service启动访问：http://127.0.0.1:56011.3.1.3.控制台选择左侧的DevTools菜单，即可进入控制台页面：在页面右侧，就可以输入请求，访问Elasticsearch了。1.3.2.ik分词器1.3.2.1.安装上传zip包，解压到Elasticsearch目录的plugins目录中：ik分词器地址使用unzip命令解压：1unzip elasticsearch-analysis-ik-5.6.3.zip -d ik-analyzer然后重启elasticsearch：1.3.2.2.测试在kibana控制台输入下面的请求：12345POST _analyze&#123; &quot;analyzer&quot;: &quot;ik_max_word&quot;, &quot;text&quot;: &quot;这是一个简单的例子&quot;&#125;运行得到结果：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&#123; &quot;tokens&quot;: [ &#123; &quot;token&quot;: &quot;这是&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 2, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 0 &#125;, &#123; &quot;token&quot;: &quot;一个&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 4, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 1 &#125;, &#123; &quot;token&quot;: &quot;一&quot;, &quot;start_offset&quot;: 2, &quot;end_offset&quot;: 3, &quot;type&quot;: &quot;TYPE_CNUM&quot;, &quot;position&quot;: 2 &#125;, &#123; &quot;token&quot;: &quot;个&quot;, &quot;start_offset&quot;: 3, &quot;end_offset&quot;: 4, &quot;type&quot;: &quot;COUNT&quot;, &quot;position&quot;: 3 &#125;, &#123; &quot;token&quot;: &quot;简单&quot;, &quot;start_offset&quot;: 4, &quot;end_offset&quot;: 6, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 4 &#125;, &#123; &quot;token&quot;: &quot;的&quot;, &quot;start_offset&quot;: 6, &quot;end_offset&quot;: 7, &quot;type&quot;: &quot;CN_CHAR&quot;, &quot;position&quot;: 5 &#125;, &#123; &quot;token&quot;: &quot;例子&quot;, &quot;start_offset&quot;: 7, &quot;end_offset&quot;: 9, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 6 &#125; ]&#125;1.3.3.Head 插件1.3.3.1.概念elasticsearch-head是一个界面化的集群操作和管理工具，可以对集群进行傻瓜式操作。你可以通过插件把它集成到elasticsearch（5.0版本后不支持此方式）,也可以安装成一个独立webapp。elasticsearch-head插件是使用JavaScript开发的，依赖Node.js库，使用Grunt工具构建，所以等会我们要安装elasticsearch-head，还需要先安装Node.js和Grunt。1.3.3.2.应用elasticsearch-head主要的作用有以下这些方面：可以直接浏览数据支持JSON验证器支持重复请求计时器支持使用javascript表达式变换结果查看方便的查看集群状态，包括有多少个replication，多少个shared查看索引的状态,显示集群的状态提供便捷的查询方式，通过选择的方式查询搜索接口能够查询集群中原始json或表格格式的检索数据请求方法(get、put、post、delete),查询json数据,节点和路径绿色，最健康的状态，代表所有的分片包括备份都可用黄色，基本的分片可用，但是备份不可用（也可能是没有备份），下文有提到红色，部分的分片可用，表明分片有一部分损坏。此时执行查询部分数据仍然可以查到，遇到这种情况，还是赶快解决比较好灰色，未连接到elasticsearch服务1.3.3.3.注意事项前端是用nodejs编写。因为是前端技术直接访问es库，所以es必须开放对外接口，而es head又有比较高的权限，可以删除任何节点，且不带安全验证，授权，因此在实际生产环境要慎用。1.3.3.4.友链文档入口：link1.3.4.esrally（压测）性能工具esrally主要功能如下：自动创建、压测和销毁 es 集群可分 es 版本管理压测数据和方案完善的压测数据展示，支持不同压测之间的数据对比分析，也可以将数据存储到指定的es中进行二次分析支持收集 JVM 详细信息，比如内存、GC等数据来定位性能问题源码地址参考：[1]link1[2]link21.3.5.x-pack性能监控(待)获取进程运行时资源与状态信息并存储至es中。可通过kibana查看es、logstash性能指标，试用版包括集群状态、延迟、索引速率、检索速率、内存、cpu、io、磁盘、文件量等还可以看到集群数据负载均衡时的情况。商用版还支持安全、告警等功能1.3.6.es-sql(待)用sql查询elasticsearch的工具，将封装复杂的dsl语句封装成sql1.3.7.Logstash 安装与导入数据(待)数据处理管。采样各种样式、大小的数据来源，实时解析和转换数据，选择众多输出目标导出数据1.3.8.beats(待)轻量级的数据采集工具，可监控网络流量、日志数据、进程信息（负载、内存、磁盘等），支持docker镜像的file采集1.3.9.在 Docker 容器中运行 Elasticsearch，Kibana 和 Cerebro(待)搭建Cerebro Elasticsearch文档入口：link2.操作索引2.1.基本概念1）Cluster：集群。ES可以作为一个独立的单个搜索服务器。不过，为了处理大型数据集，实现容错和高可用性，ES可以运行在许多互相合作的服务器上。这些服务器的集合称为集群。2）Node：节点。形成集群的每个服务器称为节点。3）Shard：分片。当有大量的文档时，由于内存的限制、磁盘处理能力不足、无法足够快的响应客户端的请求等，一个节点可能不够。这种情况下，数据可以分为较小的分片。每个分片放到不同的服务器上。当你查询的索引分布在多个分片上时，ES会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即：这个过程对用户来说是透明的。4）Replia：副本。为提高查询吞吐量或实现高可用性，可以使用分片副本。副本是一个分片的精确复制，每个分片可以有零个或多个副本。ES中可以有许多相同的分片，其中之一被选择更改索引操作，这种特殊的分片称为主分片。当主分片丢失时，如：该分片所在的数据不可用时，集群将副本提升为新的主分片。5）全文检索:全文检索就是对一篇文章进行索引，可以根据关键字搜索，类似于mysql里的like语句。全文索引就是把内容根据词的意义进行分词，然后分别创建索引，例如”你们的激情是因为什么事情来的” 可能会被分词成：“你们“，”激情“，“什么事情“，”来“ 等token，这样当你搜索“你们” 或者 “激情” 都会把这句搜出来。Elasticsearch也是基于Lucene的全文检索库，本质也是存储数据，很多概念与MySQL类似的。- GET：获取请求对象的当前状态。 - POST：改变对象的当前状态。 - PUT：创建一个对象。 - DELETE：销毁对象。 - HEAD：请求获取对象的基础信息。对比mysql关系图例：关系型数据库中的数据库（DataBase），等价于ES中的索引（Index）一个数据库下面有N张表（Table），等价于1个索引Index下面有N多类型（Type），一个数据库表（Table）下的数据由多行（ROW）多列（column，属性）组成，等价于1个Type由多个文档（Document）和多Field组成。在一个关系型数据库里面，schema定义了表、每个表的字段，还有表和字段之间的关系。 与之对应的，在ES中：Mapping定义索引下的Type的字段处理规则，即索引如何建立、索引类型、是否保存原始索引JSON文档、是否压缩原始JSON文档、是否需要分词处理、如何进行分词处理等。在数据库中的增insert、删delete、改update、查search操作等价于ES中的增PUT/POST、删Delete、改_update、查GET.详细说明：概念说明索引库（indices)indices是index的复数，代表许多的索引类型（type）类型是模拟mysql中的table概念，一个索引库下可以有不同类型的索引，比如商品索引，订单索引，其数据格式不同。不过这会导致索引库混乱，因此未来版本中会移除这个概念文档（document）存入索引库原始的数据。比如每一条商品信息，就是一个文档字段（field）文档中的属性映射配置（mappings）字段的数据类型、属性、是否索引、是否存储等特性与Lucene和solr中的概念类似。另，在SolrCloud中，有一些集群相关的概念，在Elasticsearch也有类似的：索引集（Indices，index的复数）：逻辑上的完整索引分片（shard）：数据拆分后的各个部分副本（replica）：每个分片的复制要注意的是：Elasticsearch本身就是分布式的，因此即便你只有一个节点，Elasticsearch默认也会对你的数据进行分片和副本操作，当你向集群添加新数据时，数据也会在新加入的节点中进行平衡。2.2.创建索引2.2.1.语法Elasticsearch采用Rest风格API，因此其API就是一次http请求，你可以用任何工具发起http请求创建索引的请求格式：请求方式：PUT请求路径：/索引库名请求参数：json格式：123456&#123; "settings": &#123; "number_of_shards": 3, "number_of_replicas": 2 &#125;&#125;settings：索引库的设置number_of_shards：分片数量number_of_replicas：副本数量2.2.2.使用kibana创建kibana的控制台，可以对http请求进行简化，示例：相当于是省去了elasticsearch的服务器地址2.3.查看索引设置Get请求可以帮我们查看索引信息语法1GET /索引库名或者，使用GET *来查询所有索引库配置：2.4.删除索引删除索引使用DELETE请求语法1DELETE /索引库名用HEAD请求，查看索引是否存在：2.5.映射配置索引有了，接下来肯定是添加数据。但是，在添加数据之前必须定义映射。映射是定义文档的过程，文档包含哪些字段，这些字段是否保存，是否索引，是否分词等只有配置清楚，Elasticsearch才会帮我们进行索引库的创建（不一定）2.5.1.创建映射字段语法请求方式依然是PUT1234567891011PUT /索引库名/_mapping/类型名称&#123; &quot;properties&quot;: &#123; &quot;字段名&quot;: &#123; &quot;type&quot;: &quot;类型&quot;, &quot;index&quot;: true， &quot;store&quot;: true， &quot;analyzer&quot;: &quot;分词器&quot; &#125; &#125;&#125;类型名称：就是前面将的type的概念，类似于数据库中的不同表字段名：任意填写 ，可以指定许多属性，例如：type：类型，可以是text、long、short、date、integer、object等index：是否索引，默认为truestore：是否存储，默认为falseanalyzer：分词器，这里的ik_max_word即使用ik分词器示例发起请求：12345678910111213141516PUT wind/_mapping/books&#123; "properties": &#123; "title": &#123; "type": "text", "analyzer": "ik_max_word" &#125;, "images": &#123; "type": "keyword", "index": "false" &#125;, "price": &#123; "type": "float" &#125; &#125;&#125;响应结果：123&#123; &quot;acknowledged&quot;: true&#125;2.5.2.查看映射关系语法：1GET /索引库名/_mapping示例：1GET /wind/_mapping响应：123456789101112131415161718192021&#123; "wind": &#123; "mappings": &#123; "books": &#123; "properties": &#123; "images": &#123; "type": "keyword", "index": false &#125;, "price": &#123; "type": "float" &#125;, "title": &#123; "type": "text", "analyzer": "ik_max_word" &#125; &#125; &#125; &#125; &#125;&#125;2.5.3.字段属性详解2.5.3.1.typeElasticsearch中支持的数据类型非常丰富：这里提几个关键的：String类型，又分两种：text：可分词，不可参与聚合keyword：不可分词，数据会作为完整字段进行匹配，可以参与聚合Numerical：数值类型，分两类基本数据类型：long、interger、short、byte、double、float、half_float浮点数的高精度类型：scaled_float需要指定一个精度因子，比如10或100。elasticsearch会把真实值乘以这个因子后存储，取出时再还原。Date：日期类型elasticsearch可以对日期格式化为字符串存储，但是建议我们存储为毫秒值，存储为long，节省空间。2.5.3.2.indexindex影响字段的索引情况。true：字段会被索引，则可以用来进行搜索。默认值就是truefalse：字段不会被索引，不能用来搜索index的默认值就是true，也就是说你不进行任何配置，所有字段都会被索引。但是有些字段是我们不希望被索引的，比如商品的图片信息，就需要手动设置index为false。2.5.3.3.store是否将数据进行额外存储。在学习lucene和solr时，我们知道如果一个字段的store设置为false，那么在文档列表中就不会有这个字段的值，用户的搜索结果中不会显示出来。但是在Elasticsearch中，即便store设置为false，也可以搜索到结果。原因是Elasticsearch在创建文档索引时，会将文档中的原始数据备份，保存到一个叫做_source的属性中。而且我们可以通过过滤_source来选择哪些要显示，哪些不显示。而如果设置store为true，就会在_source以外额外存储一份数据，多余，因此一般我们都会将store设置为false，事实上，store的默认值就是false。2.5.3.4.boost激励因子，这个与lucene中一样，用的不多，可参考官方文档：2.6.新增数据2.6.1.随机生成id通过POST请求，可以向一个已经存在的索引库中添加数据。语法：1234POST /索引库名/类型名&#123; &quot;key&quot;:&quot;value&quot;&#125;示例：123456POST /wind/books/&#123; "title":"时间管理", "images":"http://image.xxx.com/12345.jpg", "price":99.00&#125;响应：12345678910111213&#123; "_index": "wind", "_type": "books", "_id": "AWxkohRi4Sn5GW_x380G", "_version": 1, "result": "created", "_shards": &#123; "total": 1, "successful": 1, "failed": 0 &#125;, "created": true&#125;通过kibana查看数据123456get _search&#123; "query":&#123; "match_all":&#123;&#125; &#125;&#125;1234567891011&#123; "_index": "wind", "_type": "books", "_id": "AWxkohRi4Sn5GW_x380G", "_score": 1, "_source": &#123; "title": "时间管理", "images": "http://image.xxx.com/12345.jpg", "price": 99 &#125; &#125;_source：源文档信息，所有的数据都在里面。_id：这条文档的唯一标示，与文档自己的id字段没有关联2.6.2.自定义id如果想要自己新增的时候指定id，可以这么做：1234POST /索引库名/类型/id值&#123; ...&#125;示例：123456POST /wind/books/2&#123; "title":"时间简史", "images":"http://image.xxx.com/13453.jpg", "price":66.00&#125;得到的数据：123456789101112&#123; "_index": "wind", "_type": "books", "_id": "2", "_version": 1, "found": true, "_source": &#123; "title": "时间简史", "images": "http://image.xxx.com/13453.jpg", "price": 66 &#125;&#125;2.6.3.智能判断在学习Solr在新增数据时，只能使用提前配置好映射属性的字段，否则就会报错。不过在Elasticsearch中并没有这样的规定。事实上Elasticsearch非常智能，你不需要给索引库设置任何mapping映射，它也可以根据你输入的数据来判断类型，动态添加数据映射。测试一下：12345678POST /wind/books/3&#123; "title":"其他书籍", "images":"http://image.xxx.com/39871.jpg", "price":66.00, "stock": 200, "saleable":true&#125;这里额外添加了stock库存，和saleable是否上架两个字段。结果：1234567891011121314&#123; "_index": "wind", "_type": "books", "_id": "3", "_version": 1, "found": true, "_source": &#123; "title": "其他书籍", "images": "http://image.xxx.com/39871.jpg", "price": 66, "stock": 200, "saleable": true &#125;&#125;在看下索引库的映射关系GET _mapping:123456789101112131415161718192021222324252627&#123; "wind ": &#123; "mappings": &#123; "books": &#123; "properties": &#123; "images": &#123; "type": "keyword", "index": false &#125;, "price": &#123; "type": "float" &#125;, "saleable": &#123; "type": "boolean" &#125;, "stock": &#123; "type": "long" &#125;, "title": &#123; "type": "text", "analyzer": "ik_max_word" &#125; &#125; &#125; &#125; &#125;&#125;stock和saleable都被成功映射了。2.7.修改数据把刚才新增的请求方式改为PUT，就是修改了。不过修改必须指定id，id对应文档存在，则修改id对应文档不存在，则新增比如，我们把id为3的数据进行修改：12345678PUT /wind/books/3&#123; "title":"其他类型书籍", "images":"http://image.xxx.com/23241.jpg", "price":66.00, "stock": 1000, "saleable":true&#125;结果：1234567891011121314&#123; "_index": "wind", "_type": "books", "_id": "3", "_version": 2, "found": true, "_source": &#123; "title": "其他类型书籍", "images": "http://image.xxx.com/23241.jpg", "price": 66, "stock": 1000, "saleable": true &#125;&#125;2.8.删除数据删除使用DELETE请求，同样，需要根据id进行删除：语法1DELETE /索引库名/类型名/id值3.查询我们从4块来讲查询：基本查询_source过滤结果过滤高级查询排序3.1.基本查询：基本语法12345678GET /索引库名/_search&#123; "query":&#123; "查询类型":&#123; "查询条件":"查询条件值" &#125; &#125;&#125;这里的query代表一个查询对象，里面可以有不同的查询属性查询类型：例如：match_all， match，term ， range 等等查询条件：查询条件会根据类型的不同，写法也有差异，后面详细讲解3.1.1 查询所有（match_all)示例：123456GET /wind/_search&#123; "query":&#123; "match_all": &#123;&#125; &#125;&#125;query：代表查询对象match_all：代表查询所有took：查询花费时间，单位是毫秒time_out：是否超时_shards：分片信息hits：搜索结果总览对象total：搜索到的总条数max_score：所有结果中文档得分的最高分hits：搜索结果的文档对象数组，每个元素是一条搜索到的文档信息_index：索引库_type：文档类型_id：文档id_score：文档得分_source：文档的源数据3.1.2 匹配查询（match）我们先加入一条数据，便于测试：123456PUT /wind/books/3&#123; "title":"经济管理", "images":"http://image.xxx.com/2249122.jpg", "price":89.00&#125;or关系match类型查询，会把查询条件进行分词，然后进行查询,多个词条之间是or的关系12345678GET /wind/_search&#123; "query":&#123; "match":&#123; "title":"经济管理" &#125; &#125;&#125;结果：1234567891011121314151617181920212223242526272829303132333435363738&#123; "took": 2, "timed_out": false, "_shards": &#123; "total": 1, "successful": 1, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 2, "max_score": 4.120749, "hits": [ &#123; "_index": "wind", "_type": "books", "_id": "3", "_score": 4.120749, "_source": &#123; "title": "经济管理", "images": "http://image.xxx.com/2249122.jpg", "price": 89 &#125; &#125;, &#123; "_index": "wind", "_type": "books", "_id": "AWxkrFq84Sn5GW_x380S", "_score": 0.5051683, "_source": &#123; "title": "时间管理", "images": "http://image.xxx.com/12345.jpg", "price": 99 &#125; &#125; ] &#125;&#125;在上面的案例中，不仅会查询“经济管理”，而且与管理相关的都会查询到，多个词之间是or的关系。and关系某些情况下，我们需要更精确查找，我们希望这个关系变成and，可以这样做：1234567891011GET /wind/_search&#123; "query":&#123; "match": &#123; "title": &#123; "query": "经济管理", "operator": "and" &#125; &#125; &#125;&#125;结果：123456789101112131415161718192021222324252627&#123; "took": 24, "timed_out": false, "_shards": &#123; "total": 1, "successful": 1, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 1, "max_score": 4.120749, "hits": [ &#123; "_index": "wind", "_type": "books", "_id": "3", "_score": 4.120749, "_source": &#123; "title": "经济管理", "images": "http://image.xxx.com/2249122.jpg", "price": 89 &#125; &#125; ] &#125;&#125;本例中，只有同时包含经济和管理的词条才会被搜索到。or和and之间？在 or 与 and 间二选一有点过于非黑即白。 如果用户给定的条件分词后有 5 个查询词项，想查找只包含其中 4 个词的文档，该如何处理？将 operator 操作符参数设置成 and 只会将此文档排除。有时候这正是我们期望的，但在全文搜索的大多数应用场景下，我们既想包含那些可能相关的文档，同时又排除那些不太相关的。换句话说，我们想要处于中间某种结果。match 查询支持 minimum_should_match 最小匹配参数， 这让我们可以指定必须匹配的词项数用来表示一个文档是否相关。我们可以将其设置为某个具体数字，更常用的做法是将其设置为一个百分数，因为我们无法控制用户搜索时输入的单词数量：1234567891011GET /wind/_search&#123; "query":&#123; "match":&#123; "title":&#123; "query":"经济模式管理", "minimum_should_match": "75%" &#125; &#125; &#125;&#125;本例中，搜索语句可以分为3个词，如果使用and关系，需要同时满足3个词才会被搜索到。这里我们采用最小品牌数：75%，那么也就是说只要匹配到总词条数量的75%即可，这里3*75% 约等于2。所以只要包含2个词条就算满足条件了。3.1.3 多字段查询（multi_match）multi_match与match类似，不同的是它可以在多个字段中查询123456789GET /wind/_search&#123; "query":&#123; "multi_match": &#123; "query": "管理", "fields": [ "title", "subTitle" ] &#125; &#125;&#125;本例中，在title字段和subtitle字段中查询管理这个词3.1.4 词条匹配(term)term 查询被用于精确值 匹配，这些精确值可能是数字、时间、布尔或者那些未分词的字符串12345678GET /wind/_search&#123; "query":&#123; "term":&#123; "price":99.00 &#125; &#125;&#125;3.1.5 多词条精确匹配(terms)terms 查询和 term 查询一样，但它允许你指定多值进行匹配。如果这个字段包含了指定值中的任何一个值，那么这个文档满足条件：12345678GET /wind/_search&#123; "query":&#123; "terms":&#123; "price":[66.00,89.00,99.00] &#125; &#125;&#125;3.2.结果过滤默认情况下，elasticsearch在搜索的结果中，会把文档中保存在_source的所有字段都返回。如果我们只想获取其中的部分字段，我们可以添加_source的过滤3.2.1.直接指定字段示例：123456789GET /wind/_search&#123; "_source": ["title","price"], "query": &#123; "term": &#123; "price": 99 &#125; &#125;&#125;3.2.2.指定includes和excludes我们也可以通过：includes：来指定想要显示的字段excludes：来指定不想要显示的字段二者都是可选的。示例：1234567891011GET /wind/_search&#123; "_source": &#123; "includes":["title","price"] &#125;, "query": &#123; "term": &#123; "price": 89 &#125; &#125;&#125;与下面的结果将是一样的：1234567891011GET /wind/_search&#123; "_source": &#123; "excludes": ["images"] &#125;, "query": &#123; "term": &#123; "price": 89 &#125; &#125;&#125;3.3 高级查询3.3.1 布尔组合（bool)bool把各种其它查询通过must（与）、must_not（非）、should（或）的方式进行组合12345678910GET /wind/_search&#123; "query":&#123; "bool":&#123; "must": &#123; "match": &#123; "title": "管理" &#125;&#125;, "must_not": &#123; "match": &#123; "title": "经济" &#125;&#125;, "should": &#123; "match": &#123; "title": "时间" &#125;&#125; &#125; &#125;&#125;3.3.2 范围查询(range)range 查询找出那些落在指定区间内的数字或者时间1234567891011GET /wind/_search&#123; "query":&#123; "range": &#123; "price": &#123; "gte": 10.0, "lt": 100.00 &#125; &#125; &#125;&#125;range查询允许以下字符：操作符说明gt大于gte大于等于lt小于lte小于等于3.3.3 模糊查询(fuzzy)我们新增一个商品：123456POST /wind/books/4&#123; "title":"cherish时间", "images":"http://image.xxx.com/213131.jpg", "price":79.00&#125;fuzzy 查询是 term 查询的模糊等价。它允许用户搜索词条与实际词条的拼写出现偏差，但是偏差的编辑距离不得超过2：12345678GET /wind/_search&#123; "query": &#123; "fuzzy": &#123; "title": "cherism" &#125; &#125;&#125;上面的查询，也能查询到我们可以通过fuzziness来指定允许的编辑距离：1234567891011GET /wind/_search&#123; "query": &#123; "fuzzy": &#123; "title": &#123; "value":"cherism", "fuzziness":1 &#125; &#125; &#125;&#125;3.4 过滤(filter)条件查询中进行过滤所有的查询都会影响到文档的评分及排名。如果我们需要在查询结果中进行过滤，并且不希望过滤条件影响评分，那么就不要把过滤条件作为查询条件来用。而是使用filter方式：1234567891011GET /wind/_search&#123; "query":&#123; "bool":&#123; "must":&#123; "match": &#123; "title": "时间管理" &#125;&#125;, "filter":&#123; "range":&#123;"price":&#123;"gt":20.00,"lt":200.00&#125;&#125; &#125; &#125; &#125;&#125;注意：filter中还可以再次进行bool组合条件过滤。无查询条件，直接过滤如果一次查询只有过滤，没有查询条件，不希望进行评分，我们可以使用constant_score取代只有 filter 语句的 bool 查询。在性能上是完全相同的，但对于提高查询简洁性和清晰度有很大帮助。123456789GET /wind/_search&#123; "query":&#123; "constant_score": &#123; "filter": &#123; "range":&#123;"price":&#123;"gt":20.00,"lt":200.00&#125;&#125; &#125; &#125;&#125;3.5 排序3.5.1 单字段排序sort 可以让我们按照不同的字段进行排序，并且通过order指定排序的方式123456789101112131415GET /wind/_search&#123; "query": &#123; "match": &#123; "title": "时间管理" &#125; &#125;, "sort": [ &#123; "price": &#123; "order": "asc" &#125; &#125; ]&#125;3.5.2 多字段排序假定我们想要结合使用 price和 _score（得分） 进行查询，并且匹配的结果首先按照价格排序，然后按照相关性得分排序：123456789101112131415GET wind/books/_search&#123; "query":&#123; "bool":&#123; "must":&#123; "match": &#123; "title": "时间管理" &#125;&#125;, "filter":&#123; "range":&#123;"price":&#123;"gt":20,"lt":200&#125;&#125; &#125; &#125; &#125;, "sort": [ &#123; "price": &#123; "order": "desc" &#125;&#125;, &#123; "_score": &#123; "order": "desc" &#125;&#125; ]&#125;4. 聚合aggregations聚合可以让我们极其方便的实现对数据的统计、分析。例如：什么类型的书籍最受欢迎？这些书的平均价格、最高价格、最低价格？这些书每月的销售情况如何？实现这些统计功能的比数据库的sql要方便的多，而且查询速度非常快，可以实现实时搜索效果。4.1 基本概念Elasticsearch中的聚合，包含多种类型，最常用的两种，一个叫桶，一个叫度量：桶（bucket）桶的作用，是按照某种方式对数据进行分组，每一组数据在ES中称为一个桶，例如根据国籍对人划分，可以得到中国桶、英国桶，日本桶……或者我们按照年龄段对人进行划分：0-10,10-20,20-30,30-40等。Elasticsearch中提供的划分桶的方式有很多：Date Histogram Aggregation：根据日期阶梯分组，例如给定阶梯为周，会自动每周分为一组Histogram Aggregation：根据数值阶梯分组，与日期类似Terms Aggregation：根据词条内容分组，词条内容完全匹配的为一组Range Aggregation：数值和日期的范围分组，指定开始和结束，然后按段分组……综上所述，发现bucket aggregations 只负责对数据进行分组，并不进行计算，因此往往bucket中往往会嵌套另一种聚合：metrics aggregations即度量度量（metrics）分组完成以后，我们一般会对组中的数据进行聚合运算，例如求平均值、最大、最小、求和等，这些在ES中称为度量比较常用的一些度量聚合方式：Avg Aggregation：求平均值Max Aggregation：求最大值Min Aggregation：求最小值Percentiles Aggregation：求百分比Stats Aggregation：同时返回avg、max、min、sum、count等Sum Aggregation：求和Top hits Aggregation：求前几Value Count Aggregation：求总数……为了测试聚合，先批量导入一些数据创建索引：12345678910111213141516171819PUT /cars&#123; "settings": &#123; "number_of_shards": 1, "number_of_replicas": 0 &#125;, "mappings": &#123; "transactions": &#123; "properties": &#123; "color": &#123; "type": "keyword" &#125;, "make": &#123; "type": "keyword" &#125; &#125; &#125; &#125;&#125;注意：在ES中，需要进行聚合、排序、过滤的字段其处理方式比较特殊，因此不能被分词。这里将color和make这两个文字类型的字段设置为keyword类型，这个类型不会被分词，将来就可以参与聚合导入数据1234567891011121314151617POST /cars/transactions/_bulk&#123; "index": &#123;&#125;&#125;&#123; "price" : 10000, "color" : "red", "make" : "honda", "sold" : "2014-10-28" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 20000, "color" : "red", "make" : "honda", "sold" : "2014-11-05" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 30000, "color" : "green", "make" : "ford", "sold" : "2014-05-18" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 15000, "color" : "blue", "make" : "toyota", "sold" : "2014-07-02" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 12000, "color" : "green", "make" : "toyota", "sold" : "2014-08-19" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 20000, "color" : "red", "make" : "honda", "sold" : "2014-11-05" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 80000, "color" : "red", "make" : "bmw", "sold" : "2014-01-01" &#125;&#123; "index": &#123;&#125;&#125;&#123; "price" : 25000, "color" : "blue", "make" : "ford", "sold" : "2014-02-12" &#125;4.2 聚合为桶首先，我们按照 汽车的颜色color来划分桶1234567891011GET /cars/_search&#123; "size" : 0, "aggs" : &#123; "popular_colors" : &#123; "terms" : &#123; "field" : "color" &#125; &#125; &#125;&#125;size： 查询条数，这里设置为0，因为我们不关心搜索到的数据，只关心聚合结果，提高效率aggs：声明这是一个聚合查询，是aggregations的缩写popular_colors：给这次聚合起一个名字，任意。terms：划分桶的方式，这里是根据词条划分field：划分桶的字段结果：1234567891011121314151617181920212223242526272829303132333435&#123; "took": 1, "timed_out": false, "_shards": &#123; "total": 1, "successful": 1, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 8, "max_score": 0, "hits": [] &#125;, "aggregations": &#123; "popular_colors": &#123; "doc_count_error_upper_bound": 0, "sum_other_doc_count": 0, "buckets": [ &#123; "key": "red", "doc_count": 4 &#125;, &#123; "key": "blue", "doc_count": 2 &#125;, &#123; "key": "green", "doc_count": 2 &#125; ] &#125; &#125;&#125;hits：查询结果为空，因为我们设置了size为0aggregations：聚合的结果popular_colors：我们定义的聚合名称buckets：查找到的桶，每个不同的color字段值都会形成一个桶key：这个桶对应的color字段的值doc_count：这个桶中的文档数量通过聚合的结果我们发现，目前红色的小车比较畅销！4.3 桶内度量前面的例子告诉我们每个桶里面的文档数量，这很有用。 但通常，我们的应用需要提供更复杂的文档度量。 例如，每种颜色汽车的平均价格是多少？因此，我们需要告诉Elasticsearch使用哪个字段，使用何种度量方式进行运算，这些信息要嵌套在桶内，度量的运算会基于桶内的文档进行现在，我们为刚刚的聚合结果添加 求价格平均值的度量：123456789101112131415161718GET /cars/_search&#123; "size" : 0, "aggs" : &#123; "popular_colors" : &#123; "terms" : &#123; "field" : "color" &#125;, "aggs":&#123; "avg_price": &#123; "avg": &#123; "field": "price" &#125; &#125; &#125; &#125; &#125;&#125;aggs：我们在上一个aggs(popular_colors)中添加新的aggs。可见度量也是一个聚合,度量是在桶内的聚合avg_price：聚合的名称avg：度量的类型，这里是求平均值field：度量运算的字段结果：12345678910111213141516171819202122232425262728293031... "aggregations": &#123; "popular_colors": &#123; "doc_count_error_upper_bound": 0, "sum_other_doc_count": 0, "buckets": [ &#123; "key": "red", "doc_count": 4, "avg_price": &#123; "value": 32500 &#125; &#125;, &#123; "key": "blue", "doc_count": 2, "avg_price": &#123; "value": 20000 &#125; &#125;, &#123; "key": "green", "doc_count": 2, "avg_price": &#123; "value": 21000 &#125; &#125; ] &#125; &#125;...可以看到每个桶中都有自己的avg_price字段，这是度量聚合的结果4.4 桶内嵌套桶刚刚的案例中，我们在桶内嵌套度量运算。事实上桶不仅可以嵌套运算， 还可以再嵌套其它桶。也就是说在每个分组中，再分更多组。比如：我们想统计每种颜色的汽车中，分别属于哪个制造商，按照make字段再进行分桶1234567891011121314151617181920212223GET /cars/_search&#123; "size" : 0, "aggs" : &#123; "popular_colors" : &#123; "terms" : &#123; "field" : "color" &#125;, "aggs":&#123; "avg_price": &#123; "avg": &#123; "field": "price" &#125; &#125;, "maker":&#123; "terms":&#123; "field":"make" &#125; &#125; &#125; &#125; &#125;&#125;原来的color桶和avg计算我们不变maker：在嵌套的aggs下新添一个桶，叫做makerterms：桶的划分类型依然是词条filed：这里根据make字段进行划分部分结果：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374...&#123;"aggregations": &#123; "popular_colors": &#123; "doc_count_error_upper_bound": 0, "sum_other_doc_count": 0, "buckets": [ &#123; "key": "red", "doc_count": 4, "maker": &#123; "doc_count_error_upper_bound": 0, "sum_other_doc_count": 0, "buckets": [ &#123; "key": "honda", "doc_count": 3 &#125;, &#123; "key": "bmw", "doc_count": 1 &#125; ] &#125;, "avg_price": &#123; "value": 32500 &#125; &#125;, &#123; "key": "blue", "doc_count": 2, "maker": &#123; "doc_count_error_upper_bound": 0, "sum_other_doc_count": 0, "buckets": [ &#123; "key": "ford", "doc_count": 1 &#125;, &#123; "key": "toyota", "doc_count": 1 &#125; ] &#125;, "avg_price": &#123; "value": 20000 &#125; &#125;, &#123; "key": "green", "doc_count": 2, "maker": &#123; "doc_count_error_upper_bound": 0, "sum_other_doc_count": 0, "buckets": [ &#123; "key": "ford", "doc_count": 1 &#125;, &#123; "key": "toyota", "doc_count": 1 &#125; ] &#125;, "avg_price": &#123; "value": 21000 &#125; &#125; ] &#125; &#125;&#125;...我们可以看到，新的聚合maker被嵌套在原来每一个color的桶中。每个颜色下面都根据 make字段进行了分组我们能读取到的信息：红色车共有4辆红色车的平均售价是 $32，500 美元。其中3辆是 Honda 本田制造，1辆是 BMW 宝马制造。4.5.划分桶的其它方式前面讲了，划分桶的方式有很多，例如：Date Histogram Aggregation：根据日期阶梯分组，例如给定阶梯为周，会自动每周分为一组Histogram Aggregation：根据数值阶梯分组，与日期类似Terms Aggregation：根据词条内容分组，词条内容完全匹配的为一组Range Aggregation：数值和日期的范围分组，指定开始和结束，然后按段分组刚刚的案例中，我们采用的是Terms Aggregation，即根据词条划分桶。接下来，我们再学习几个比较实用的：4.5.1.阶梯分桶Histogram原理：histogram是把数值类型的字段，按照一定的阶梯大小进行分组。你需要指定一个阶梯值（interval）来划分阶梯大小。举例：比如你有价格字段，如果你设定interval的值为200，那么阶梯就会是这样的：0，200，400，600，…上面列出的是每个阶梯的key，也是区间的启点。如果一件商品的价格是450，会落入哪个阶梯区间呢？计算公式如下：1bucket_key = Math.floor((value - offset) / interval) * interval + offsetvalue：就是当前数据的值，本例中是450offset：起始偏移量，默认为0interval：阶梯间隔，比如200因此你得到的key = Math.floor((450 - 0) / 200) * 200 + 0 = 400操作一下：比如，我们对汽车的价格进行分组，指定间隔interval为5000：123456789101112GET /cars/_search&#123; "size":0, "aggs":&#123; "price":&#123; "histogram": &#123; "field": "price", "interval": 5000 &#125; &#125; &#125;&#125;结果：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081&#123; "took": 21, "timed_out": false, "_shards": &#123; "total": 5, "successful": 5, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 8, "max_score": 0, "hits": [] &#125;, "aggregations": &#123; "price": &#123; "buckets": [ &#123; "key": 10000, "doc_count": 2 &#125;, &#123; "key": 15000, "doc_count": 1 &#125;, &#123; "key": 20000, "doc_count": 2 &#125;, &#123; "key": 25000, "doc_count": 1 &#125;, &#123; "key": 30000, "doc_count": 1 &#125;, &#123; "key": 35000, "doc_count": 0 &#125;, &#123; "key": 40000, "doc_count": 0 &#125;, &#123; "key": 45000, "doc_count": 0 &#125;, &#123; "key": 50000, "doc_count": 0 &#125;, &#123; "key": 55000, "doc_count": 0 &#125;, &#123; "key": 60000, "doc_count": 0 &#125;, &#123; "key": 65000, "doc_count": 0 &#125;, &#123; "key": 70000, "doc_count": 0 &#125;, &#123; "key": 75000, "doc_count": 0 &#125;, &#123; "key": 80000, "doc_count": 1 &#125; ] &#125; &#125;&#125;你会发现，中间有大量的文档数量为0 的桶，看起来很丑。可以增加一个参数min_doc_count为1，来约束最少文档数量为1，这样文档数量为0的桶会被过滤示例：12345678910111213GET /cars/_search&#123; "size":0, "aggs":&#123; "price":&#123; "histogram": &#123; "field": "price", "interval": 5000, "min_doc_count": 1 &#125; &#125; &#125;&#125;结果：123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; "took": 15, "timed_out": false, "_shards": &#123; "total": 5, "successful": 5, "skipped": 0, "failed": 0 &#125;, "hits": &#123; "total": 8, "max_score": 0, "hits": [] &#125;, "aggregations": &#123; "price": &#123; "buckets": [ &#123; "key": 10000, "doc_count": 2 &#125;, &#123; "key": 15000, "doc_count": 1 &#125;, &#123; "key": 20000, "doc_count": 2 &#125;, &#123; "key": 25000, "doc_count": 1 &#125;, &#123; "key": 30000, "doc_count": 1 &#125;, &#123; "key": 80000, "doc_count": 1 &#125; ] &#125; &#125;&#125;如果你用kibana将结果变为柱形图，会更好看4.5.2.范围分桶range范围分桶与阶梯分桶类似，也是把数字按照阶段进行分组，只不过range方式需要你自己指定每一组的起始和结束大小。]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
        <tag>搜索引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch安装]]></title>
    <url>%2F2019%2F08%2F30%2Fes%2Felasticsearch%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[1.安装步骤1.1从官网下载linux版本的elasticsearch安装程序，https://www.elastic.co/cn/downloads/elasticsearch （最好直接通过迅雷工具下载，普通下载太慢了）目前的版本是7.x的：elasticsearch-7.0.1-linux-x86_64.tar.gz1.2centos服务器安装ftp软件（winSCP等），通过ftp软件把elasticsearch-7.0.1-linux-x86_64.tar.gz上传到服务器的opt/mysoft目录下。1.3tar -zxvf elasticsearch-7.0.1-linux-x86_64.tar.gz解压到当前目录下，mv elasticsearch-7.0.1/ elasticsearch重命名为elasticsearch1.4通过命令：sh /opt/mysoft/elasticsearch/bin/elasticsearch启动ElasticSearch。启动后会因为权限可能抛出异常：123456解决方法： 1.添加用户：useradd elastic 2.给用户授权：chown -R elastic:elastic /opt/mysoft/elasticserch/ 3.切换用户：su elastic 4.通过命令重写启动服务：sh /opt/mysoft/elasticsearch/bin/elasticsearch -d 5.输入：curl http://localhost:92001.5vi /opt/mysoft/elasticserch/config/elasticsearch.yml修改network配置本机的ip地址和端口号：network.host: 192.168.248.100http.port: 9200修改之后可能会出现问题：p11WARN [o.e.b.JNANatives ] unable to install syscall filter使用新的linux版本就没问题了p2123ERROR: bootstrap checks failedmax file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]max number of threads [1024] for user [lishang] likely too low, increase to at least [2048]解决：切换到root用户，编辑limits.conf 添加类似如下内容vi /etc/security/limits.conf添加如下内容:1234* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096p31max number of threads [1024] for user [lish] likely too low, increase to at least解决：切换到root用户，进入limits.d目录下修改配置文件。vi /etc/security/limits.d/90-nproc.conf修改如下内容：123* soft nproc 1024#修改为* soft nproc 2048p41max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]解决：切换到root用户修改配置sysctl.confvi /etc/sysctl.conf添加下面配置:vm.max_map_count=655360并执行命令：sysctl -pp51max file descriptors [4096] for elasticsearch process likely too low, increase to at least [65536]解决：修改切换到root用户修改配置limits.conf 添加下面两行命令:vi /etc/security/limits.conf12* hard nofile 65536* soft nofile 65536p6启动Elasticsearch时使用新建的elk用户，启动时报错：1max number of threads [3895] for user [elk] is too low, increase to at least [4096]解决方法：root用户修改：vi/etc/security/limits.d/90-nproc.conf123* soft nproc 2048修改为：* soft nproc 4096p712ERROR: [1] bootstrap checks failedsystem call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk。解决：Centos6不支持SecComp，而ES5.2.0默认bootstrap.system_call_filter为true禁用：在elasticsearch.yml中配置 bootstrap.system_call_filter为false，注意要在Memory下面添加:12bootstrap.memory_lock: false bootstrap.system_call_filter: false再次启动ElasticSearch就能够正常启动了。p81the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured注意：在外部访问ElasticSearch服务的时候，要停掉CentOS的防火墙，不然仍旧无法访问。防火墙查看命令：service iptables status防火墙停止命令：service iptables stopElasticSeach后台启动命令：sh/opt/mysoft/elasticsearch/bin/elasticsearch -d]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
</search>
